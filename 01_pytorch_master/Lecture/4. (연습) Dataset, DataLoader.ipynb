{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "미니배치, 이터레이션, 에포크 참조  \n",
    "https://wikidocs.net/55580"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "from torch.utils.data import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 퀴즈 (Easy)  \n",
    "1) 당뇨병 데이터셋에 대해서 로지스틱 회귀 모델을 구현한다면 첫번째 레이어의 노드 수는 몇개가 되어야 할까요??   \n",
    "2) data_loader에서 샘플들을 가져온다면 샘플들의 전체 모양은 어떻게 될까요?  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression,self).__init__()\n",
    "        self.linear_layer = nn.Linear(3,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.L1 = nn.Linear(8, 6)\n",
    "        self.L2 = nn.Linear(6, 4)\n",
    "        self.L3 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.L1(x))\n",
    "        x = self.sigmoid(self.L2(x))\n",
    "        x = self.sigmoid(self.L3(x))\n",
    "        y_pred = self.sigmoid(x)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, xy_dataset):\n",
    "        # 커스텀 데이터셋 클래스의 생성자를 정의\n",
    "        # 데이터를 불러와서 torch.tensor로 할당 및 전처리한다.\n",
    "        self.x_data = torch.from_numpy(xy_dataset[:,0:-1])\n",
    "        self.y_data = torch.from_numpy(xy_dataset[:,[-1]])\n",
    "        print(f'X shape : {self.x_data.shape} | Y shape : {self.y_data.shape}')\n",
    "\n",
    "    # 매직 메소드 : 함수 이름 앞, 뒤로 underbar 2개를 붙인 매소드\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = LogisticRegressionModel()\n",
    "bce_loss = nn.BCELoss(reduction='mean')\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, samples in enumerate(data_loader):\n",
    "        x_train, y_train = samples\n",
    "        y_pred = model(x_train)\n",
    "        loss = bce_loss(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx % 10 == 0):\n",
    "            print(f'Epoch: {epoch+1:4d}/{epochs} Batch {batch_idx+1:4d}/{len(data_loader)} \\\n",
    "                    Loss: {loss.item():4f}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:    1/1000 Batch    1/8                     Loss: 0.654221\n",
      "Epoch:    2/1000 Batch    1/8                     Loss: 0.653550\n",
      "Epoch:    3/1000 Batch    1/8                     Loss: 0.653214\n",
      "Epoch:    4/1000 Batch    1/8                     Loss: 0.653043\n",
      "Epoch:    5/1000 Batch    1/8                     Loss: 0.652867\n",
      "Epoch:    6/1000 Batch    1/8                     Loss: 0.652573\n",
      "Epoch:    7/1000 Batch    1/8                     Loss: 0.652074\n",
      "Epoch:    8/1000 Batch    1/8                     Loss: 0.651267\n",
      "Epoch:    9/1000 Batch    1/8                     Loss: 0.650001\n",
      "Epoch:   10/1000 Batch    1/8                     Loss: 0.648068\n",
      "Epoch:   11/1000 Batch    1/8                     Loss: 0.645215\n",
      "Epoch:   12/1000 Batch    1/8                     Loss: 0.641179\n",
      "Epoch:   13/1000 Batch    1/8                     Loss: 0.635779\n",
      "Epoch:   14/1000 Batch    1/8                     Loss: 0.629052\n",
      "Epoch:   15/1000 Batch    1/8                     Loss: 0.621369\n",
      "Epoch:   16/1000 Batch    1/8                     Loss: 0.613392\n",
      "Epoch:   17/1000 Batch    1/8                     Loss: 0.605852\n",
      "Epoch:   18/1000 Batch    1/8                     Loss: 0.599305\n",
      "Epoch:   19/1000 Batch    1/8                     Loss: 0.594016\n",
      "Epoch:   20/1000 Batch    1/8                     Loss: 0.589980\n",
      "Epoch:   21/1000 Batch    1/8                     Loss: 0.587030\n",
      "Epoch:   22/1000 Batch    1/8                     Loss: 0.584940\n",
      "Epoch:   23/1000 Batch    1/8                     Loss: 0.583500\n",
      "Epoch:   24/1000 Batch    1/8                     Loss: 0.582538\n",
      "Epoch:   25/1000 Batch    1/8                     Loss: 0.581925\n",
      "Epoch:   26/1000 Batch    1/8                     Loss: 0.581564\n",
      "Epoch:   27/1000 Batch    1/8                     Loss: 0.581383\n",
      "Epoch:   28/1000 Batch    1/8                     Loss: 0.581332\n",
      "Epoch:   29/1000 Batch    1/8                     Loss: 0.581372\n",
      "Epoch:   30/1000 Batch    1/8                     Loss: 0.581468\n",
      "Epoch:   31/1000 Batch    1/8                     Loss: 0.581588\n",
      "Epoch:   32/1000 Batch    1/8                     Loss: 0.581706\n",
      "Epoch:   33/1000 Batch    1/8                     Loss: 0.581802\n",
      "Epoch:   34/1000 Batch    1/8                     Loss: 0.581868\n",
      "Epoch:   35/1000 Batch    1/8                     Loss: 0.581900\n",
      "Epoch:   36/1000 Batch    1/8                     Loss: 0.581899\n",
      "Epoch:   37/1000 Batch    1/8                     Loss: 0.581867\n",
      "Epoch:   38/1000 Batch    1/8                     Loss: 0.581808\n",
      "Epoch:   39/1000 Batch    1/8                     Loss: 0.581729\n",
      "Epoch:   40/1000 Batch    1/8                     Loss: 0.581635\n",
      "Epoch:   41/1000 Batch    1/8                     Loss: 0.581531\n",
      "Epoch:   42/1000 Batch    1/8                     Loss: 0.581423\n",
      "Epoch:   43/1000 Batch    1/8                     Loss: 0.581314\n",
      "Epoch:   44/1000 Batch    1/8                     Loss: 0.581207\n",
      "Epoch:   45/1000 Batch    1/8                     Loss: 0.581105\n",
      "Epoch:   46/1000 Batch    1/8                     Loss: 0.581009\n",
      "Epoch:   47/1000 Batch    1/8                     Loss: 0.580920\n",
      "Epoch:   48/1000 Batch    1/8                     Loss: 0.580839\n",
      "Epoch:   49/1000 Batch    1/8                     Loss: 0.580765\n",
      "Epoch:   50/1000 Batch    1/8                     Loss: 0.580699\n",
      "Epoch:   51/1000 Batch    1/8                     Loss: 0.580641\n",
      "Epoch:   52/1000 Batch    1/8                     Loss: 0.580590\n",
      "Epoch:   53/1000 Batch    1/8                     Loss: 0.580545\n",
      "Epoch:   54/1000 Batch    1/8                     Loss: 0.580507\n",
      "Epoch:   55/1000 Batch    1/8                     Loss: 0.580475\n",
      "Epoch:   56/1000 Batch    1/8                     Loss: 0.580449\n",
      "Epoch:   57/1000 Batch    1/8                     Loss: 0.580428\n",
      "Epoch:   58/1000 Batch    1/8                     Loss: 0.580412\n",
      "Epoch:   59/1000 Batch    1/8                     Loss: 0.580400\n",
      "Epoch:   60/1000 Batch    1/8                     Loss: 0.580393\n",
      "Epoch:   61/1000 Batch    1/8                     Loss: 0.580390\n",
      "Epoch:   62/1000 Batch    1/8                     Loss: 0.580391\n",
      "Epoch:   63/1000 Batch    1/8                     Loss: 0.580395\n",
      "Epoch:   64/1000 Batch    1/8                     Loss: 0.580403\n",
      "Epoch:   65/1000 Batch    1/8                     Loss: 0.580413\n",
      "Epoch:   66/1000 Batch    1/8                     Loss: 0.580426\n",
      "Epoch:   67/1000 Batch    1/8                     Loss: 0.580442\n",
      "Epoch:   68/1000 Batch    1/8                     Loss: 0.580460\n",
      "Epoch:   69/1000 Batch    1/8                     Loss: 0.580480\n",
      "Epoch:   70/1000 Batch    1/8                     Loss: 0.580501\n",
      "Epoch:   71/1000 Batch    1/8                     Loss: 0.580524\n",
      "Epoch:   72/1000 Batch    1/8                     Loss: 0.580549\n",
      "Epoch:   73/1000 Batch    1/8                     Loss: 0.580574\n",
      "Epoch:   74/1000 Batch    1/8                     Loss: 0.580600\n",
      "Epoch:   75/1000 Batch    1/8                     Loss: 0.580627\n",
      "Epoch:   76/1000 Batch    1/8                     Loss: 0.580653\n",
      "Epoch:   77/1000 Batch    1/8                     Loss: 0.580680\n",
      "Epoch:   78/1000 Batch    1/8                     Loss: 0.580706\n",
      "Epoch:   79/1000 Batch    1/8                     Loss: 0.580731\n",
      "Epoch:   80/1000 Batch    1/8                     Loss: 0.580755\n",
      "Epoch:   81/1000 Batch    1/8                     Loss: 0.580778\n",
      "Epoch:   82/1000 Batch    1/8                     Loss: 0.580799\n",
      "Epoch:   83/1000 Batch    1/8                     Loss: 0.580819\n",
      "Epoch:   84/1000 Batch    1/8                     Loss: 0.580836\n",
      "Epoch:   85/1000 Batch    1/8                     Loss: 0.580851\n",
      "Epoch:   86/1000 Batch    1/8                     Loss: 0.580863\n",
      "Epoch:   87/1000 Batch    1/8                     Loss: 0.580873\n",
      "Epoch:   88/1000 Batch    1/8                     Loss: 0.580881\n",
      "Epoch:   89/1000 Batch    1/8                     Loss: 0.580885\n",
      "Epoch:   90/1000 Batch    1/8                     Loss: 0.580887\n",
      "Epoch:   91/1000 Batch    1/8                     Loss: 0.580886\n",
      "Epoch:   92/1000 Batch    1/8                     Loss: 0.580882\n",
      "Epoch:   93/1000 Batch    1/8                     Loss: 0.580875\n",
      "Epoch:   94/1000 Batch    1/8                     Loss: 0.580866\n",
      "Epoch:   95/1000 Batch    1/8                     Loss: 0.580853\n",
      "Epoch:   96/1000 Batch    1/8                     Loss: 0.580839\n",
      "Epoch:   97/1000 Batch    1/8                     Loss: 0.580822\n",
      "Epoch:   98/1000 Batch    1/8                     Loss: 0.580804\n",
      "Epoch:   99/1000 Batch    1/8                     Loss: 0.580783\n",
      "Epoch:  100/1000 Batch    1/8                     Loss: 0.580760\n",
      "Epoch:  101/1000 Batch    1/8                     Loss: 0.580736\n",
      "Epoch:  102/1000 Batch    1/8                     Loss: 0.580711\n",
      "Epoch:  103/1000 Batch    1/8                     Loss: 0.580685\n",
      "Epoch:  104/1000 Batch    1/8                     Loss: 0.580657\n",
      "Epoch:  105/1000 Batch    1/8                     Loss: 0.580630\n",
      "Epoch:  106/1000 Batch    1/8                     Loss: 0.580601\n",
      "Epoch:  107/1000 Batch    1/8                     Loss: 0.580572\n",
      "Epoch:  108/1000 Batch    1/8                     Loss: 0.580543\n",
      "Epoch:  109/1000 Batch    1/8                     Loss: 0.580515\n",
      "Epoch:  110/1000 Batch    1/8                     Loss: 0.580486\n",
      "Epoch:  111/1000 Batch    1/8                     Loss: 0.580457\n",
      "Epoch:  112/1000 Batch    1/8                     Loss: 0.580429\n",
      "Epoch:  113/1000 Batch    1/8                     Loss: 0.580401\n",
      "Epoch:  114/1000 Batch    1/8                     Loss: 0.580373\n",
      "Epoch:  115/1000 Batch    1/8                     Loss: 0.580346\n",
      "Epoch:  116/1000 Batch    1/8                     Loss: 0.580320\n",
      "Epoch:  117/1000 Batch    1/8                     Loss: 0.580294\n",
      "Epoch:  118/1000 Batch    1/8                     Loss: 0.580269\n",
      "Epoch:  119/1000 Batch    1/8                     Loss: 0.580244\n",
      "Epoch:  120/1000 Batch    1/8                     Loss: 0.580220\n",
      "Epoch:  121/1000 Batch    1/8                     Loss: 0.580197\n",
      "Epoch:  122/1000 Batch    1/8                     Loss: 0.580174\n",
      "Epoch:  123/1000 Batch    1/8                     Loss: 0.580153\n",
      "Epoch:  124/1000 Batch    1/8                     Loss: 0.580131\n",
      "Epoch:  125/1000 Batch    1/8                     Loss: 0.580111\n",
      "Epoch:  126/1000 Batch    1/8                     Loss: 0.580091\n",
      "Epoch:  127/1000 Batch    1/8                     Loss: 0.580071\n",
      "Epoch:  128/1000 Batch    1/8                     Loss: 0.580052\n",
      "Epoch:  129/1000 Batch    1/8                     Loss: 0.580034\n",
      "Epoch:  130/1000 Batch    1/8                     Loss: 0.580017\n",
      "Epoch:  131/1000 Batch    1/8                     Loss: 0.579999\n",
      "Epoch:  132/1000 Batch    1/8                     Loss: 0.579983\n",
      "Epoch:  133/1000 Batch    1/8                     Loss: 0.579966\n",
      "Epoch:  134/1000 Batch    1/8                     Loss: 0.579951\n",
      "Epoch:  135/1000 Batch    1/8                     Loss: 0.579935\n",
      "Epoch:  136/1000 Batch    1/8                     Loss: 0.579920\n",
      "Epoch:  137/1000 Batch    1/8                     Loss: 0.579906\n",
      "Epoch:  138/1000 Batch    1/8                     Loss: 0.579891\n",
      "Epoch:  139/1000 Batch    1/8                     Loss: 0.579877\n",
      "Epoch:  140/1000 Batch    1/8                     Loss: 0.579864\n",
      "Epoch:  141/1000 Batch    1/8                     Loss: 0.579850\n",
      "Epoch:  142/1000 Batch    1/8                     Loss: 0.579837\n",
      "Epoch:  143/1000 Batch    1/8                     Loss: 0.579824\n",
      "Epoch:  144/1000 Batch    1/8                     Loss: 0.579811\n",
      "Epoch:  145/1000 Batch    1/8                     Loss: 0.579799\n",
      "Epoch:  146/1000 Batch    1/8                     Loss: 0.579787\n",
      "Epoch:  147/1000 Batch    1/8                     Loss: 0.579774\n",
      "Epoch:  148/1000 Batch    1/8                     Loss: 0.579762\n",
      "Epoch:  149/1000 Batch    1/8                     Loss: 0.579751\n",
      "Epoch:  150/1000 Batch    1/8                     Loss: 0.579739\n",
      "Epoch:  151/1000 Batch    1/8                     Loss: 0.579727\n",
      "Epoch:  152/1000 Batch    1/8                     Loss: 0.579716\n",
      "Epoch:  153/1000 Batch    1/8                     Loss: 0.579704\n",
      "Epoch:  154/1000 Batch    1/8                     Loss: 0.579693\n",
      "Epoch:  155/1000 Batch    1/8                     Loss: 0.579681\n",
      "Epoch:  156/1000 Batch    1/8                     Loss: 0.579670\n",
      "Epoch:  157/1000 Batch    1/8                     Loss: 0.579659\n",
      "Epoch:  158/1000 Batch    1/8                     Loss: 0.579647\n",
      "Epoch:  159/1000 Batch    1/8                     Loss: 0.579636\n",
      "Epoch:  160/1000 Batch    1/8                     Loss: 0.579625\n",
      "Epoch:  161/1000 Batch    1/8                     Loss: 0.579614\n",
      "Epoch:  162/1000 Batch    1/8                     Loss: 0.579602\n",
      "Epoch:  163/1000 Batch    1/8                     Loss: 0.579591\n",
      "Epoch:  164/1000 Batch    1/8                     Loss: 0.579580\n",
      "Epoch:  165/1000 Batch    1/8                     Loss: 0.579569\n",
      "Epoch:  166/1000 Batch    1/8                     Loss: 0.579557\n",
      "Epoch:  167/1000 Batch    1/8                     Loss: 0.579546\n",
      "Epoch:  168/1000 Batch    1/8                     Loss: 0.579534\n",
      "Epoch:  169/1000 Batch    1/8                     Loss: 0.579523\n",
      "Epoch:  170/1000 Batch    1/8                     Loss: 0.579511\n",
      "Epoch:  171/1000 Batch    1/8                     Loss: 0.579500\n",
      "Epoch:  172/1000 Batch    1/8                     Loss: 0.579488\n",
      "Epoch:  173/1000 Batch    1/8                     Loss: 0.579476\n",
      "Epoch:  174/1000 Batch    1/8                     Loss: 0.579465\n",
      "Epoch:  175/1000 Batch    1/8                     Loss: 0.579453\n",
      "Epoch:  176/1000 Batch    1/8                     Loss: 0.579441\n",
      "Epoch:  177/1000 Batch    1/8                     Loss: 0.579429\n",
      "Epoch:  178/1000 Batch    1/8                     Loss: 0.579417\n",
      "Epoch:  179/1000 Batch    1/8                     Loss: 0.579404\n",
      "Epoch:  180/1000 Batch    1/8                     Loss: 0.579392\n",
      "Epoch:  181/1000 Batch    1/8                     Loss: 0.579380\n",
      "Epoch:  182/1000 Batch    1/8                     Loss: 0.579367\n",
      "Epoch:  183/1000 Batch    1/8                     Loss: 0.579355\n",
      "Epoch:  184/1000 Batch    1/8                     Loss: 0.579342\n",
      "Epoch:  185/1000 Batch    1/8                     Loss: 0.579329\n",
      "Epoch:  186/1000 Batch    1/8                     Loss: 0.579316\n",
      "Epoch:  187/1000 Batch    1/8                     Loss: 0.579303\n",
      "Epoch:  188/1000 Batch    1/8                     Loss: 0.579290\n",
      "Epoch:  189/1000 Batch    1/8                     Loss: 0.579276\n",
      "Epoch:  190/1000 Batch    1/8                     Loss: 0.579263\n",
      "Epoch:  191/1000 Batch    1/8                     Loss: 0.579249\n",
      "Epoch:  192/1000 Batch    1/8                     Loss: 0.579236\n",
      "Epoch:  193/1000 Batch    1/8                     Loss: 0.579222\n",
      "Epoch:  194/1000 Batch    1/8                     Loss: 0.579208\n",
      "Epoch:  195/1000 Batch    1/8                     Loss: 0.579194\n",
      "Epoch:  196/1000 Batch    1/8                     Loss: 0.579179\n",
      "Epoch:  197/1000 Batch    1/8                     Loss: 0.579165\n",
      "Epoch:  198/1000 Batch    1/8                     Loss: 0.579151\n",
      "Epoch:  199/1000 Batch    1/8                     Loss: 0.579136\n",
      "Epoch:  200/1000 Batch    1/8                     Loss: 0.579121\n",
      "Epoch:  201/1000 Batch    1/8                     Loss: 0.579106\n",
      "Epoch:  202/1000 Batch    1/8                     Loss: 0.579092\n",
      "Epoch:  203/1000 Batch    1/8                     Loss: 0.579076\n",
      "Epoch:  204/1000 Batch    1/8                     Loss: 0.579061\n",
      "Epoch:  205/1000 Batch    1/8                     Loss: 0.579046\n",
      "Epoch:  206/1000 Batch    1/8                     Loss: 0.579031\n",
      "Epoch:  207/1000 Batch    1/8                     Loss: 0.579015\n",
      "Epoch:  208/1000 Batch    1/8                     Loss: 0.579000\n",
      "Epoch:  209/1000 Batch    1/8                     Loss: 0.578984\n",
      "Epoch:  210/1000 Batch    1/8                     Loss: 0.578968\n",
      "Epoch:  211/1000 Batch    1/8                     Loss: 0.578952\n",
      "Epoch:  212/1000 Batch    1/8                     Loss: 0.578936\n",
      "Epoch:  213/1000 Batch    1/8                     Loss: 0.578920\n",
      "Epoch:  214/1000 Batch    1/8                     Loss: 0.578904\n",
      "Epoch:  215/1000 Batch    1/8                     Loss: 0.578888\n",
      "Epoch:  216/1000 Batch    1/8                     Loss: 0.578872\n",
      "Epoch:  217/1000 Batch    1/8                     Loss: 0.578856\n",
      "Epoch:  218/1000 Batch    1/8                     Loss: 0.578840\n",
      "Epoch:  219/1000 Batch    1/8                     Loss: 0.578823\n",
      "Epoch:  220/1000 Batch    1/8                     Loss: 0.578807\n",
      "Epoch:  221/1000 Batch    1/8                     Loss: 0.578791\n",
      "Epoch:  222/1000 Batch    1/8                     Loss: 0.578774\n",
      "Epoch:  223/1000 Batch    1/8                     Loss: 0.578758\n",
      "Epoch:  224/1000 Batch    1/8                     Loss: 0.578742\n",
      "Epoch:  225/1000 Batch    1/8                     Loss: 0.578725\n",
      "Epoch:  226/1000 Batch    1/8                     Loss: 0.578709\n",
      "Epoch:  227/1000 Batch    1/8                     Loss: 0.578692\n",
      "Epoch:  228/1000 Batch    1/8                     Loss: 0.578676\n",
      "Epoch:  229/1000 Batch    1/8                     Loss: 0.578659\n",
      "Epoch:  230/1000 Batch    1/8                     Loss: 0.578643\n",
      "Epoch:  231/1000 Batch    1/8                     Loss: 0.578627\n",
      "Epoch:  232/1000 Batch    1/8                     Loss: 0.578610\n",
      "Epoch:  233/1000 Batch    1/8                     Loss: 0.578594\n",
      "Epoch:  234/1000 Batch    1/8                     Loss: 0.578577\n",
      "Epoch:  235/1000 Batch    1/8                     Loss: 0.578561\n",
      "Epoch:  236/1000 Batch    1/8                     Loss: 0.578545\n",
      "Epoch:  237/1000 Batch    1/8                     Loss: 0.578528\n",
      "Epoch:  238/1000 Batch    1/8                     Loss: 0.578512\n",
      "Epoch:  239/1000 Batch    1/8                     Loss: 0.578496\n",
      "Epoch:  240/1000 Batch    1/8                     Loss: 0.578480\n",
      "Epoch:  241/1000 Batch    1/8                     Loss: 0.578464\n",
      "Epoch:  242/1000 Batch    1/8                     Loss: 0.578448\n",
      "Epoch:  243/1000 Batch    1/8                     Loss: 0.578431\n",
      "Epoch:  244/1000 Batch    1/8                     Loss: 0.578415\n",
      "Epoch:  245/1000 Batch    1/8                     Loss: 0.578399\n",
      "Epoch:  246/1000 Batch    1/8                     Loss: 0.578383\n",
      "Epoch:  247/1000 Batch    1/8                     Loss: 0.578367\n",
      "Epoch:  248/1000 Batch    1/8                     Loss: 0.578351\n",
      "Epoch:  249/1000 Batch    1/8                     Loss: 0.578336\n",
      "Epoch:  250/1000 Batch    1/8                     Loss: 0.578320\n",
      "Epoch:  251/1000 Batch    1/8                     Loss: 0.578304\n",
      "Epoch:  252/1000 Batch    1/8                     Loss: 0.578288\n",
      "Epoch:  253/1000 Batch    1/8                     Loss: 0.578272\n",
      "Epoch:  254/1000 Batch    1/8                     Loss: 0.578257\n",
      "Epoch:  255/1000 Batch    1/8                     Loss: 0.578241\n",
      "Epoch:  256/1000 Batch    1/8                     Loss: 0.578226\n",
      "Epoch:  257/1000 Batch    1/8                     Loss: 0.578210\n",
      "Epoch:  258/1000 Batch    1/8                     Loss: 0.578195\n",
      "Epoch:  259/1000 Batch    1/8                     Loss: 0.578179\n",
      "Epoch:  260/1000 Batch    1/8                     Loss: 0.578164\n",
      "Epoch:  261/1000 Batch    1/8                     Loss: 0.578148\n",
      "Epoch:  262/1000 Batch    1/8                     Loss: 0.578133\n",
      "Epoch:  263/1000 Batch    1/8                     Loss: 0.578118\n",
      "Epoch:  264/1000 Batch    1/8                     Loss: 0.578103\n",
      "Epoch:  265/1000 Batch    1/8                     Loss: 0.578088\n",
      "Epoch:  266/1000 Batch    1/8                     Loss: 0.578072\n",
      "Epoch:  267/1000 Batch    1/8                     Loss: 0.578057\n",
      "Epoch:  268/1000 Batch    1/8                     Loss: 0.578042\n",
      "Epoch:  269/1000 Batch    1/8                     Loss: 0.578027\n",
      "Epoch:  270/1000 Batch    1/8                     Loss: 0.578012\n",
      "Epoch:  271/1000 Batch    1/8                     Loss: 0.577998\n",
      "Epoch:  272/1000 Batch    1/8                     Loss: 0.577983\n",
      "Epoch:  273/1000 Batch    1/8                     Loss: 0.577968\n",
      "Epoch:  274/1000 Batch    1/8                     Loss: 0.577953\n",
      "Epoch:  275/1000 Batch    1/8                     Loss: 0.577938\n",
      "Epoch:  276/1000 Batch    1/8                     Loss: 0.577924\n",
      "Epoch:  277/1000 Batch    1/8                     Loss: 0.577909\n",
      "Epoch:  278/1000 Batch    1/8                     Loss: 0.577894\n",
      "Epoch:  279/1000 Batch    1/8                     Loss: 0.577880\n",
      "Epoch:  280/1000 Batch    1/8                     Loss: 0.577865\n",
      "Epoch:  281/1000 Batch    1/8                     Loss: 0.577851\n",
      "Epoch:  282/1000 Batch    1/8                     Loss: 0.577836\n",
      "Epoch:  283/1000 Batch    1/8                     Loss: 0.577822\n",
      "Epoch:  284/1000 Batch    1/8                     Loss: 0.577808\n",
      "Epoch:  285/1000 Batch    1/8                     Loss: 0.577793\n",
      "Epoch:  286/1000 Batch    1/8                     Loss: 0.577779\n",
      "Epoch:  287/1000 Batch    1/8                     Loss: 0.577765\n",
      "Epoch:  288/1000 Batch    1/8                     Loss: 0.577751\n",
      "Epoch:  289/1000 Batch    1/8                     Loss: 0.577736\n",
      "Epoch:  290/1000 Batch    1/8                     Loss: 0.577722\n",
      "Epoch:  291/1000 Batch    1/8                     Loss: 0.577708\n",
      "Epoch:  292/1000 Batch    1/8                     Loss: 0.577694\n",
      "Epoch:  293/1000 Batch    1/8                     Loss: 0.577680\n",
      "Epoch:  294/1000 Batch    1/8                     Loss: 0.577666\n",
      "Epoch:  295/1000 Batch    1/8                     Loss: 0.577652\n",
      "Epoch:  296/1000 Batch    1/8                     Loss: 0.577638\n",
      "Epoch:  297/1000 Batch    1/8                     Loss: 0.577624\n",
      "Epoch:  298/1000 Batch    1/8                     Loss: 0.577611\n",
      "Epoch:  299/1000 Batch    1/8                     Loss: 0.577597\n",
      "Epoch:  300/1000 Batch    1/8                     Loss: 0.577583\n",
      "Epoch:  301/1000 Batch    1/8                     Loss: 0.577569\n",
      "Epoch:  302/1000 Batch    1/8                     Loss: 0.577555\n",
      "Epoch:  303/1000 Batch    1/8                     Loss: 0.577542\n",
      "Epoch:  304/1000 Batch    1/8                     Loss: 0.577528\n",
      "Epoch:  305/1000 Batch    1/8                     Loss: 0.577514\n",
      "Epoch:  306/1000 Batch    1/8                     Loss: 0.577501\n",
      "Epoch:  307/1000 Batch    1/8                     Loss: 0.577487\n",
      "Epoch:  308/1000 Batch    1/8                     Loss: 0.577473\n",
      "Epoch:  309/1000 Batch    1/8                     Loss: 0.577460\n",
      "Epoch:  310/1000 Batch    1/8                     Loss: 0.577446\n",
      "Epoch:  311/1000 Batch    1/8                     Loss: 0.577432\n",
      "Epoch:  312/1000 Batch    1/8                     Loss: 0.577419\n",
      "Epoch:  313/1000 Batch    1/8                     Loss: 0.577405\n",
      "Epoch:  314/1000 Batch    1/8                     Loss: 0.577392\n",
      "Epoch:  315/1000 Batch    1/8                     Loss: 0.577378\n",
      "Epoch:  316/1000 Batch    1/8                     Loss: 0.577364\n",
      "Epoch:  317/1000 Batch    1/8                     Loss: 0.577351\n",
      "Epoch:  318/1000 Batch    1/8                     Loss: 0.577337\n",
      "Epoch:  319/1000 Batch    1/8                     Loss: 0.577324\n",
      "Epoch:  320/1000 Batch    1/8                     Loss: 0.577310\n",
      "Epoch:  321/1000 Batch    1/8                     Loss: 0.577297\n",
      "Epoch:  322/1000 Batch    1/8                     Loss: 0.577283\n",
      "Epoch:  323/1000 Batch    1/8                     Loss: 0.577269\n",
      "Epoch:  324/1000 Batch    1/8                     Loss: 0.577256\n",
      "Epoch:  325/1000 Batch    1/8                     Loss: 0.577242\n",
      "Epoch:  326/1000 Batch    1/8                     Loss: 0.577228\n",
      "Epoch:  327/1000 Batch    1/8                     Loss: 0.577215\n",
      "Epoch:  328/1000 Batch    1/8                     Loss: 0.577201\n",
      "Epoch:  329/1000 Batch    1/8                     Loss: 0.577187\n",
      "Epoch:  330/1000 Batch    1/8                     Loss: 0.577173\n",
      "Epoch:  331/1000 Batch    1/8                     Loss: 0.577160\n",
      "Epoch:  332/1000 Batch    1/8                     Loss: 0.577146\n",
      "Epoch:  333/1000 Batch    1/8                     Loss: 0.577132\n",
      "Epoch:  334/1000 Batch    1/8                     Loss: 0.577118\n",
      "Epoch:  335/1000 Batch    1/8                     Loss: 0.577104\n",
      "Epoch:  336/1000 Batch    1/8                     Loss: 0.577090\n",
      "Epoch:  337/1000 Batch    1/8                     Loss: 0.577076\n",
      "Epoch:  338/1000 Batch    1/8                     Loss: 0.577062\n",
      "Epoch:  339/1000 Batch    1/8                     Loss: 0.577048\n",
      "Epoch:  340/1000 Batch    1/8                     Loss: 0.577033\n",
      "Epoch:  341/1000 Batch    1/8                     Loss: 0.577019\n",
      "Epoch:  342/1000 Batch    1/8                     Loss: 0.577005\n",
      "Epoch:  343/1000 Batch    1/8                     Loss: 0.576990\n",
      "Epoch:  344/1000 Batch    1/8                     Loss: 0.576976\n",
      "Epoch:  345/1000 Batch    1/8                     Loss: 0.576961\n",
      "Epoch:  346/1000 Batch    1/8                     Loss: 0.576946\n",
      "Epoch:  347/1000 Batch    1/8                     Loss: 0.576932\n",
      "Epoch:  348/1000 Batch    1/8                     Loss: 0.576917\n",
      "Epoch:  349/1000 Batch    1/8                     Loss: 0.576902\n",
      "Epoch:  350/1000 Batch    1/8                     Loss: 0.576887\n",
      "Epoch:  351/1000 Batch    1/8                     Loss: 0.576872\n",
      "Epoch:  352/1000 Batch    1/8                     Loss: 0.576857\n",
      "Epoch:  353/1000 Batch    1/8                     Loss: 0.576841\n",
      "Epoch:  354/1000 Batch    1/8                     Loss: 0.576826\n",
      "Epoch:  355/1000 Batch    1/8                     Loss: 0.576810\n",
      "Epoch:  356/1000 Batch    1/8                     Loss: 0.576795\n",
      "Epoch:  357/1000 Batch    1/8                     Loss: 0.576779\n",
      "Epoch:  358/1000 Batch    1/8                     Loss: 0.576763\n",
      "Epoch:  359/1000 Batch    1/8                     Loss: 0.576747\n",
      "Epoch:  360/1000 Batch    1/8                     Loss: 0.576731\n",
      "Epoch:  361/1000 Batch    1/8                     Loss: 0.576715\n",
      "Epoch:  362/1000 Batch    1/8                     Loss: 0.576699\n",
      "Epoch:  363/1000 Batch    1/8                     Loss: 0.576683\n",
      "Epoch:  364/1000 Batch    1/8                     Loss: 0.576666\n",
      "Epoch:  365/1000 Batch    1/8                     Loss: 0.576649\n",
      "Epoch:  366/1000 Batch    1/8                     Loss: 0.576633\n",
      "Epoch:  367/1000 Batch    1/8                     Loss: 0.576616\n",
      "Epoch:  368/1000 Batch    1/8                     Loss: 0.576599\n",
      "Epoch:  369/1000 Batch    1/8                     Loss: 0.576582\n",
      "Epoch:  370/1000 Batch    1/8                     Loss: 0.576564\n",
      "Epoch:  371/1000 Batch    1/8                     Loss: 0.576547\n",
      "Epoch:  372/1000 Batch    1/8                     Loss: 0.576529\n",
      "Epoch:  373/1000 Batch    1/8                     Loss: 0.576511\n",
      "Epoch:  374/1000 Batch    1/8                     Loss: 0.576494\n",
      "Epoch:  375/1000 Batch    1/8                     Loss: 0.576476\n",
      "Epoch:  376/1000 Batch    1/8                     Loss: 0.576457\n",
      "Epoch:  377/1000 Batch    1/8                     Loss: 0.576439\n",
      "Epoch:  378/1000 Batch    1/8                     Loss: 0.576421\n",
      "Epoch:  379/1000 Batch    1/8                     Loss: 0.576402\n",
      "Epoch:  380/1000 Batch    1/8                     Loss: 0.576383\n",
      "Epoch:  381/1000 Batch    1/8                     Loss: 0.576364\n",
      "Epoch:  382/1000 Batch    1/8                     Loss: 0.576345\n",
      "Epoch:  383/1000 Batch    1/8                     Loss: 0.576326\n",
      "Epoch:  384/1000 Batch    1/8                     Loss: 0.576306\n",
      "Epoch:  385/1000 Batch    1/8                     Loss: 0.576287\n",
      "Epoch:  386/1000 Batch    1/8                     Loss: 0.576267\n",
      "Epoch:  387/1000 Batch    1/8                     Loss: 0.576247\n",
      "Epoch:  388/1000 Batch    1/8                     Loss: 0.576227\n",
      "Epoch:  389/1000 Batch    1/8                     Loss: 0.576207\n",
      "Epoch:  390/1000 Batch    1/8                     Loss: 0.576187\n",
      "Epoch:  391/1000 Batch    1/8                     Loss: 0.576166\n",
      "Epoch:  392/1000 Batch    1/8                     Loss: 0.576145\n",
      "Epoch:  393/1000 Batch    1/8                     Loss: 0.576124\n",
      "Epoch:  394/1000 Batch    1/8                     Loss: 0.576103\n",
      "Epoch:  395/1000 Batch    1/8                     Loss: 0.576082\n",
      "Epoch:  396/1000 Batch    1/8                     Loss: 0.576060\n",
      "Epoch:  397/1000 Batch    1/8                     Loss: 0.576039\n",
      "Epoch:  398/1000 Batch    1/8                     Loss: 0.576017\n",
      "Epoch:  399/1000 Batch    1/8                     Loss: 0.575995\n",
      "Epoch:  400/1000 Batch    1/8                     Loss: 0.575973\n",
      "Epoch:  401/1000 Batch    1/8                     Loss: 0.575951\n",
      "Epoch:  402/1000 Batch    1/8                     Loss: 0.575928\n",
      "Epoch:  403/1000 Batch    1/8                     Loss: 0.575906\n",
      "Epoch:  404/1000 Batch    1/8                     Loss: 0.575883\n",
      "Epoch:  405/1000 Batch    1/8                     Loss: 0.575860\n",
      "Epoch:  406/1000 Batch    1/8                     Loss: 0.575837\n",
      "Epoch:  407/1000 Batch    1/8                     Loss: 0.575814\n",
      "Epoch:  408/1000 Batch    1/8                     Loss: 0.575790\n",
      "Epoch:  409/1000 Batch    1/8                     Loss: 0.575766\n",
      "Epoch:  410/1000 Batch    1/8                     Loss: 0.575743\n",
      "Epoch:  411/1000 Batch    1/8                     Loss: 0.575719\n",
      "Epoch:  412/1000 Batch    1/8                     Loss: 0.575694\n",
      "Epoch:  413/1000 Batch    1/8                     Loss: 0.575670\n",
      "Epoch:  414/1000 Batch    1/8                     Loss: 0.575646\n",
      "Epoch:  415/1000 Batch    1/8                     Loss: 0.575621\n",
      "Epoch:  416/1000 Batch    1/8                     Loss: 0.575596\n",
      "Epoch:  417/1000 Batch    1/8                     Loss: 0.575571\n",
      "Epoch:  418/1000 Batch    1/8                     Loss: 0.575546\n",
      "Epoch:  419/1000 Batch    1/8                     Loss: 0.575520\n",
      "Epoch:  420/1000 Batch    1/8                     Loss: 0.575495\n",
      "Epoch:  421/1000 Batch    1/8                     Loss: 0.575469\n",
      "Epoch:  422/1000 Batch    1/8                     Loss: 0.575443\n",
      "Epoch:  423/1000 Batch    1/8                     Loss: 0.575417\n",
      "Epoch:  424/1000 Batch    1/8                     Loss: 0.575391\n",
      "Epoch:  425/1000 Batch    1/8                     Loss: 0.575365\n",
      "Epoch:  426/1000 Batch    1/8                     Loss: 0.575339\n",
      "Epoch:  427/1000 Batch    1/8                     Loss: 0.575312\n",
      "Epoch:  428/1000 Batch    1/8                     Loss: 0.575285\n",
      "Epoch:  429/1000 Batch    1/8                     Loss: 0.575258\n",
      "Epoch:  430/1000 Batch    1/8                     Loss: 0.575231\n",
      "Epoch:  431/1000 Batch    1/8                     Loss: 0.575204\n",
      "Epoch:  432/1000 Batch    1/8                     Loss: 0.575176\n",
      "Epoch:  433/1000 Batch    1/8                     Loss: 0.575149\n",
      "Epoch:  434/1000 Batch    1/8                     Loss: 0.575121\n",
      "Epoch:  435/1000 Batch    1/8                     Loss: 0.575093\n",
      "Epoch:  436/1000 Batch    1/8                     Loss: 0.575065\n",
      "Epoch:  437/1000 Batch    1/8                     Loss: 0.575037\n",
      "Epoch:  438/1000 Batch    1/8                     Loss: 0.575009\n",
      "Epoch:  439/1000 Batch    1/8                     Loss: 0.574980\n",
      "Epoch:  440/1000 Batch    1/8                     Loss: 0.574951\n",
      "Epoch:  441/1000 Batch    1/8                     Loss: 0.574923\n",
      "Epoch:  442/1000 Batch    1/8                     Loss: 0.574894\n",
      "Epoch:  443/1000 Batch    1/8                     Loss: 0.574865\n",
      "Epoch:  444/1000 Batch    1/8                     Loss: 0.574836\n",
      "Epoch:  445/1000 Batch    1/8                     Loss: 0.574806\n",
      "Epoch:  446/1000 Batch    1/8                     Loss: 0.574777\n",
      "Epoch:  447/1000 Batch    1/8                     Loss: 0.574747\n",
      "Epoch:  448/1000 Batch    1/8                     Loss: 0.574717\n",
      "Epoch:  449/1000 Batch    1/8                     Loss: 0.574687\n",
      "Epoch:  450/1000 Batch    1/8                     Loss: 0.574657\n",
      "Epoch:  451/1000 Batch    1/8                     Loss: 0.574627\n",
      "Epoch:  452/1000 Batch    1/8                     Loss: 0.574597\n",
      "Epoch:  453/1000 Batch    1/8                     Loss: 0.574567\n",
      "Epoch:  454/1000 Batch    1/8                     Loss: 0.574536\n",
      "Epoch:  455/1000 Batch    1/8                     Loss: 0.574505\n",
      "Epoch:  456/1000 Batch    1/8                     Loss: 0.574474\n",
      "Epoch:  457/1000 Batch    1/8                     Loss: 0.574443\n",
      "Epoch:  458/1000 Batch    1/8                     Loss: 0.574412\n",
      "Epoch:  459/1000 Batch    1/8                     Loss: 0.574381\n",
      "Epoch:  460/1000 Batch    1/8                     Loss: 0.574350\n",
      "Epoch:  461/1000 Batch    1/8                     Loss: 0.574318\n",
      "Epoch:  462/1000 Batch    1/8                     Loss: 0.574287\n",
      "Epoch:  463/1000 Batch    1/8                     Loss: 0.574255\n",
      "Epoch:  464/1000 Batch    1/8                     Loss: 0.574223\n",
      "Epoch:  465/1000 Batch    1/8                     Loss: 0.574191\n",
      "Epoch:  466/1000 Batch    1/8                     Loss: 0.574159\n",
      "Epoch:  467/1000 Batch    1/8                     Loss: 0.574127\n",
      "Epoch:  468/1000 Batch    1/8                     Loss: 0.574095\n",
      "Epoch:  469/1000 Batch    1/8                     Loss: 0.574062\n",
      "Epoch:  470/1000 Batch    1/8                     Loss: 0.574029\n",
      "Epoch:  471/1000 Batch    1/8                     Loss: 0.573997\n",
      "Epoch:  472/1000 Batch    1/8                     Loss: 0.573964\n",
      "Epoch:  473/1000 Batch    1/8                     Loss: 0.573931\n",
      "Epoch:  474/1000 Batch    1/8                     Loss: 0.573898\n",
      "Epoch:  475/1000 Batch    1/8                     Loss: 0.573865\n",
      "Epoch:  476/1000 Batch    1/8                     Loss: 0.573832\n",
      "Epoch:  477/1000 Batch    1/8                     Loss: 0.573798\n",
      "Epoch:  478/1000 Batch    1/8                     Loss: 0.573765\n",
      "Epoch:  479/1000 Batch    1/8                     Loss: 0.573731\n",
      "Epoch:  480/1000 Batch    1/8                     Loss: 0.573698\n",
      "Epoch:  481/1000 Batch    1/8                     Loss: 0.573664\n",
      "Epoch:  482/1000 Batch    1/8                     Loss: 0.573630\n",
      "Epoch:  483/1000 Batch    1/8                     Loss: 0.573596\n",
      "Epoch:  484/1000 Batch    1/8                     Loss: 0.573562\n",
      "Epoch:  485/1000 Batch    1/8                     Loss: 0.573528\n",
      "Epoch:  486/1000 Batch    1/8                     Loss: 0.573494\n",
      "Epoch:  487/1000 Batch    1/8                     Loss: 0.573460\n",
      "Epoch:  488/1000 Batch    1/8                     Loss: 0.573426\n",
      "Epoch:  489/1000 Batch    1/8                     Loss: 0.573391\n",
      "Epoch:  490/1000 Batch    1/8                     Loss: 0.573357\n",
      "Epoch:  491/1000 Batch    1/8                     Loss: 0.573323\n",
      "Epoch:  492/1000 Batch    1/8                     Loss: 0.573288\n",
      "Epoch:  493/1000 Batch    1/8                     Loss: 0.573254\n",
      "Epoch:  494/1000 Batch    1/8                     Loss: 0.573219\n",
      "Epoch:  495/1000 Batch    1/8                     Loss: 0.573184\n",
      "Epoch:  496/1000 Batch    1/8                     Loss: 0.573150\n",
      "Epoch:  497/1000 Batch    1/8                     Loss: 0.573115\n",
      "Epoch:  498/1000 Batch    1/8                     Loss: 0.573080\n",
      "Epoch:  499/1000 Batch    1/8                     Loss: 0.573046\n",
      "Epoch:  500/1000 Batch    1/8                     Loss: 0.573011\n",
      "Epoch:  501/1000 Batch    1/8                     Loss: 0.572976\n",
      "Epoch:  502/1000 Batch    1/8                     Loss: 0.572942\n",
      "Epoch:  503/1000 Batch    1/8                     Loss: 0.572907\n",
      "Epoch:  504/1000 Batch    1/8                     Loss: 0.572872\n",
      "Epoch:  505/1000 Batch    1/8                     Loss: 0.572838\n",
      "Epoch:  506/1000 Batch    1/8                     Loss: 0.572803\n",
      "Epoch:  507/1000 Batch    1/8                     Loss: 0.572769\n",
      "Epoch:  508/1000 Batch    1/8                     Loss: 0.572734\n",
      "Epoch:  509/1000 Batch    1/8                     Loss: 0.572700\n",
      "Epoch:  510/1000 Batch    1/8                     Loss: 0.572665\n",
      "Epoch:  511/1000 Batch    1/8                     Loss: 0.572631\n",
      "Epoch:  512/1000 Batch    1/8                     Loss: 0.572597\n",
      "Epoch:  513/1000 Batch    1/8                     Loss: 0.572563\n",
      "Epoch:  514/1000 Batch    1/8                     Loss: 0.572529\n",
      "Epoch:  515/1000 Batch    1/8                     Loss: 0.572495\n",
      "Epoch:  516/1000 Batch    1/8                     Loss: 0.572461\n",
      "Epoch:  517/1000 Batch    1/8                     Loss: 0.572427\n",
      "Epoch:  518/1000 Batch    1/8                     Loss: 0.572394\n",
      "Epoch:  519/1000 Batch    1/8                     Loss: 0.572360\n",
      "Epoch:  520/1000 Batch    1/8                     Loss: 0.572327\n",
      "Epoch:  521/1000 Batch    1/8                     Loss: 0.572294\n",
      "Epoch:  522/1000 Batch    1/8                     Loss: 0.572261\n",
      "Epoch:  523/1000 Batch    1/8                     Loss: 0.572228\n",
      "Epoch:  524/1000 Batch    1/8                     Loss: 0.572195\n",
      "Epoch:  525/1000 Batch    1/8                     Loss: 0.572163\n",
      "Epoch:  526/1000 Batch    1/8                     Loss: 0.572131\n",
      "Epoch:  527/1000 Batch    1/8                     Loss: 0.572099\n",
      "Epoch:  528/1000 Batch    1/8                     Loss: 0.572067\n",
      "Epoch:  529/1000 Batch    1/8                     Loss: 0.572036\n",
      "Epoch:  530/1000 Batch    1/8                     Loss: 0.572004\n",
      "Epoch:  531/1000 Batch    1/8                     Loss: 0.571973\n",
      "Epoch:  532/1000 Batch    1/8                     Loss: 0.571943\n",
      "Epoch:  533/1000 Batch    1/8                     Loss: 0.571912\n",
      "Epoch:  534/1000 Batch    1/8                     Loss: 0.571882\n",
      "Epoch:  535/1000 Batch    1/8                     Loss: 0.571853\n",
      "Epoch:  536/1000 Batch    1/8                     Loss: 0.571823\n",
      "Epoch:  537/1000 Batch    1/8                     Loss: 0.571794\n",
      "Epoch:  538/1000 Batch    1/8                     Loss: 0.571765\n",
      "Epoch:  539/1000 Batch    1/8                     Loss: 0.571737\n",
      "Epoch:  540/1000 Batch    1/8                     Loss: 0.571709\n",
      "Epoch:  541/1000 Batch    1/8                     Loss: 0.571681\n",
      "Epoch:  542/1000 Batch    1/8                     Loss: 0.571654\n",
      "Epoch:  543/1000 Batch    1/8                     Loss: 0.571626\n",
      "Epoch:  544/1000 Batch    1/8                     Loss: 0.571600\n",
      "Epoch:  545/1000 Batch    1/8                     Loss: 0.571573\n",
      "Epoch:  546/1000 Batch    1/8                     Loss: 0.571547\n",
      "Epoch:  547/1000 Batch    1/8                     Loss: 0.571521\n",
      "Epoch:  548/1000 Batch    1/8                     Loss: 0.571495\n",
      "Epoch:  549/1000 Batch    1/8                     Loss: 0.571470\n",
      "Epoch:  550/1000 Batch    1/8                     Loss: 0.571445\n",
      "Epoch:  551/1000 Batch    1/8                     Loss: 0.571420\n",
      "Epoch:  552/1000 Batch    1/8                     Loss: 0.571395\n",
      "Epoch:  553/1000 Batch    1/8                     Loss: 0.571371\n",
      "Epoch:  554/1000 Batch    1/8                     Loss: 0.571347\n",
      "Epoch:  555/1000 Batch    1/8                     Loss: 0.571324\n",
      "Epoch:  556/1000 Batch    1/8                     Loss: 0.571301\n",
      "Epoch:  557/1000 Batch    1/8                     Loss: 0.571278\n",
      "Epoch:  558/1000 Batch    1/8                     Loss: 0.571255\n",
      "Epoch:  559/1000 Batch    1/8                     Loss: 0.571233\n",
      "Epoch:  560/1000 Batch    1/8                     Loss: 0.571211\n",
      "Epoch:  561/1000 Batch    1/8                     Loss: 0.571190\n",
      "Epoch:  562/1000 Batch    1/8                     Loss: 0.571168\n",
      "Epoch:  563/1000 Batch    1/8                     Loss: 0.571147\n",
      "Epoch:  564/1000 Batch    1/8                     Loss: 0.571126\n",
      "Epoch:  565/1000 Batch    1/8                     Loss: 0.571106\n",
      "Epoch:  566/1000 Batch    1/8                     Loss: 0.571086\n",
      "Epoch:  567/1000 Batch    1/8                     Loss: 0.571066\n",
      "Epoch:  568/1000 Batch    1/8                     Loss: 0.571047\n",
      "Epoch:  569/1000 Batch    1/8                     Loss: 0.571027\n",
      "Epoch:  570/1000 Batch    1/8                     Loss: 0.571009\n",
      "Epoch:  571/1000 Batch    1/8                     Loss: 0.570990\n",
      "Epoch:  572/1000 Batch    1/8                     Loss: 0.570972\n",
      "Epoch:  573/1000 Batch    1/8                     Loss: 0.570954\n",
      "Epoch:  574/1000 Batch    1/8                     Loss: 0.570936\n",
      "Epoch:  575/1000 Batch    1/8                     Loss: 0.570919\n",
      "Epoch:  576/1000 Batch    1/8                     Loss: 0.570902\n",
      "Epoch:  577/1000 Batch    1/8                     Loss: 0.570885\n",
      "Epoch:  578/1000 Batch    1/8                     Loss: 0.570869\n",
      "Epoch:  579/1000 Batch    1/8                     Loss: 0.570853\n",
      "Epoch:  580/1000 Batch    1/8                     Loss: 0.570837\n",
      "Epoch:  581/1000 Batch    1/8                     Loss: 0.570822\n",
      "Epoch:  582/1000 Batch    1/8                     Loss: 0.570807\n",
      "Epoch:  583/1000 Batch    1/8                     Loss: 0.570792\n",
      "Epoch:  584/1000 Batch    1/8                     Loss: 0.570777\n",
      "Epoch:  585/1000 Batch    1/8                     Loss: 0.570763\n",
      "Epoch:  586/1000 Batch    1/8                     Loss: 0.570749\n",
      "Epoch:  587/1000 Batch    1/8                     Loss: 0.570736\n",
      "Epoch:  588/1000 Batch    1/8                     Loss: 0.570722\n",
      "Epoch:  589/1000 Batch    1/8                     Loss: 0.570709\n",
      "Epoch:  590/1000 Batch    1/8                     Loss: 0.570696\n",
      "Epoch:  591/1000 Batch    1/8                     Loss: 0.570684\n",
      "Epoch:  592/1000 Batch    1/8                     Loss: 0.570671\n",
      "Epoch:  593/1000 Batch    1/8                     Loss: 0.570659\n",
      "Epoch:  594/1000 Batch    1/8                     Loss: 0.570647\n",
      "Epoch:  595/1000 Batch    1/8                     Loss: 0.570636\n",
      "Epoch:  596/1000 Batch    1/8                     Loss: 0.570624\n",
      "Epoch:  597/1000 Batch    1/8                     Loss: 0.570613\n",
      "Epoch:  598/1000 Batch    1/8                     Loss: 0.570602\n",
      "Epoch:  599/1000 Batch    1/8                     Loss: 0.570592\n",
      "Epoch:  600/1000 Batch    1/8                     Loss: 0.570581\n",
      "Epoch:  601/1000 Batch    1/8                     Loss: 0.570571\n",
      "Epoch:  602/1000 Batch    1/8                     Loss: 0.570561\n",
      "Epoch:  603/1000 Batch    1/8                     Loss: 0.570551\n",
      "Epoch:  604/1000 Batch    1/8                     Loss: 0.570541\n",
      "Epoch:  605/1000 Batch    1/8                     Loss: 0.570532\n",
      "Epoch:  606/1000 Batch    1/8                     Loss: 0.570523\n",
      "Epoch:  607/1000 Batch    1/8                     Loss: 0.570514\n",
      "Epoch:  608/1000 Batch    1/8                     Loss: 0.570505\n",
      "Epoch:  609/1000 Batch    1/8                     Loss: 0.570496\n",
      "Epoch:  610/1000 Batch    1/8                     Loss: 0.570488\n",
      "Epoch:  611/1000 Batch    1/8                     Loss: 0.570480\n",
      "Epoch:  612/1000 Batch    1/8                     Loss: 0.570471\n",
      "Epoch:  613/1000 Batch    1/8                     Loss: 0.570463\n",
      "Epoch:  614/1000 Batch    1/8                     Loss: 0.570456\n",
      "Epoch:  615/1000 Batch    1/8                     Loss: 0.570448\n",
      "Epoch:  616/1000 Batch    1/8                     Loss: 0.570441\n",
      "Epoch:  617/1000 Batch    1/8                     Loss: 0.570433\n",
      "Epoch:  618/1000 Batch    1/8                     Loss: 0.570426\n",
      "Epoch:  619/1000 Batch    1/8                     Loss: 0.570419\n",
      "Epoch:  620/1000 Batch    1/8                     Loss: 0.570412\n",
      "Epoch:  621/1000 Batch    1/8                     Loss: 0.570406\n",
      "Epoch:  622/1000 Batch    1/8                     Loss: 0.570399\n",
      "Epoch:  623/1000 Batch    1/8                     Loss: 0.570393\n",
      "Epoch:  624/1000 Batch    1/8                     Loss: 0.570386\n",
      "Epoch:  625/1000 Batch    1/8                     Loss: 0.570380\n",
      "Epoch:  626/1000 Batch    1/8                     Loss: 0.570374\n",
      "Epoch:  627/1000 Batch    1/8                     Loss: 0.570368\n",
      "Epoch:  628/1000 Batch    1/8                     Loss: 0.570362\n",
      "Epoch:  629/1000 Batch    1/8                     Loss: 0.570357\n",
      "Epoch:  630/1000 Batch    1/8                     Loss: 0.570351\n",
      "Epoch:  631/1000 Batch    1/8                     Loss: 0.570346\n",
      "Epoch:  632/1000 Batch    1/8                     Loss: 0.570340\n",
      "Epoch:  633/1000 Batch    1/8                     Loss: 0.570335\n",
      "Epoch:  634/1000 Batch    1/8                     Loss: 0.570330\n",
      "Epoch:  635/1000 Batch    1/8                     Loss: 0.570325\n",
      "Epoch:  636/1000 Batch    1/8                     Loss: 0.570320\n",
      "Epoch:  637/1000 Batch    1/8                     Loss: 0.570316\n",
      "Epoch:  638/1000 Batch    1/8                     Loss: 0.570311\n",
      "Epoch:  639/1000 Batch    1/8                     Loss: 0.570307\n",
      "Epoch:  640/1000 Batch    1/8                     Loss: 0.570302\n",
      "Epoch:  641/1000 Batch    1/8                     Loss: 0.570298\n",
      "Epoch:  642/1000 Batch    1/8                     Loss: 0.570294\n",
      "Epoch:  643/1000 Batch    1/8                     Loss: 0.570290\n",
      "Epoch:  644/1000 Batch    1/8                     Loss: 0.570286\n",
      "Epoch:  645/1000 Batch    1/8                     Loss: 0.570282\n",
      "Epoch:  646/1000 Batch    1/8                     Loss: 0.570278\n",
      "Epoch:  647/1000 Batch    1/8                     Loss: 0.570274\n",
      "Epoch:  648/1000 Batch    1/8                     Loss: 0.570271\n",
      "Epoch:  649/1000 Batch    1/8                     Loss: 0.570267\n",
      "Epoch:  650/1000 Batch    1/8                     Loss: 0.570264\n",
      "Epoch:  651/1000 Batch    1/8                     Loss: 0.570261\n",
      "Epoch:  652/1000 Batch    1/8                     Loss: 0.570257\n",
      "Epoch:  653/1000 Batch    1/8                     Loss: 0.570254\n",
      "Epoch:  654/1000 Batch    1/8                     Loss: 0.570251\n",
      "Epoch:  655/1000 Batch    1/8                     Loss: 0.570248\n",
      "Epoch:  656/1000 Batch    1/8                     Loss: 0.570245\n",
      "Epoch:  657/1000 Batch    1/8                     Loss: 0.570243\n",
      "Epoch:  658/1000 Batch    1/8                     Loss: 0.570240\n",
      "Epoch:  659/1000 Batch    1/8                     Loss: 0.570237\n",
      "Epoch:  660/1000 Batch    1/8                     Loss: 0.570235\n",
      "Epoch:  661/1000 Batch    1/8                     Loss: 0.570232\n",
      "Epoch:  662/1000 Batch    1/8                     Loss: 0.570230\n",
      "Epoch:  663/1000 Batch    1/8                     Loss: 0.570227\n",
      "Epoch:  664/1000 Batch    1/8                     Loss: 0.570225\n",
      "Epoch:  665/1000 Batch    1/8                     Loss: 0.570223\n",
      "Epoch:  666/1000 Batch    1/8                     Loss: 0.570221\n",
      "Epoch:  667/1000 Batch    1/8                     Loss: 0.570219\n",
      "Epoch:  668/1000 Batch    1/8                     Loss: 0.570217\n",
      "Epoch:  669/1000 Batch    1/8                     Loss: 0.570215\n",
      "Epoch:  670/1000 Batch    1/8                     Loss: 0.570213\n",
      "Epoch:  671/1000 Batch    1/8                     Loss: 0.570211\n",
      "Epoch:  672/1000 Batch    1/8                     Loss: 0.570209\n",
      "Epoch:  673/1000 Batch    1/8                     Loss: 0.570207\n",
      "Epoch:  674/1000 Batch    1/8                     Loss: 0.570205\n",
      "Epoch:  675/1000 Batch    1/8                     Loss: 0.570203\n",
      "Epoch:  676/1000 Batch    1/8                     Loss: 0.570202\n",
      "Epoch:  677/1000 Batch    1/8                     Loss: 0.570200\n",
      "Epoch:  678/1000 Batch    1/8                     Loss: 0.570198\n",
      "Epoch:  679/1000 Batch    1/8                     Loss: 0.570196\n",
      "Epoch:  680/1000 Batch    1/8                     Loss: 0.570195\n",
      "Epoch:  681/1000 Batch    1/8                     Loss: 0.570193\n",
      "Epoch:  682/1000 Batch    1/8                     Loss: 0.570191\n",
      "Epoch:  683/1000 Batch    1/8                     Loss: 0.570189\n",
      "Epoch:  684/1000 Batch    1/8                     Loss: 0.570188\n",
      "Epoch:  685/1000 Batch    1/8                     Loss: 0.570186\n",
      "Epoch:  686/1000 Batch    1/8                     Loss: 0.570184\n",
      "Epoch:  687/1000 Batch    1/8                     Loss: 0.570182\n",
      "Epoch:  688/1000 Batch    1/8                     Loss: 0.570180\n",
      "Epoch:  689/1000 Batch    1/8                     Loss: 0.570178\n",
      "Epoch:  690/1000 Batch    1/8                     Loss: 0.570176\n",
      "Epoch:  691/1000 Batch    1/8                     Loss: 0.570174\n",
      "Epoch:  692/1000 Batch    1/8                     Loss: 0.570172\n",
      "Epoch:  693/1000 Batch    1/8                     Loss: 0.570170\n",
      "Epoch:  694/1000 Batch    1/8                     Loss: 0.570168\n",
      "Epoch:  695/1000 Batch    1/8                     Loss: 0.570166\n",
      "Epoch:  696/1000 Batch    1/8                     Loss: 0.570164\n",
      "Epoch:  697/1000 Batch    1/8                     Loss: 0.570162\n",
      "Epoch:  698/1000 Batch    1/8                     Loss: 0.570160\n",
      "Epoch:  699/1000 Batch    1/8                     Loss: 0.570157\n",
      "Epoch:  700/1000 Batch    1/8                     Loss: 0.570155\n",
      "Epoch:  701/1000 Batch    1/8                     Loss: 0.570152\n",
      "Epoch:  702/1000 Batch    1/8                     Loss: 0.570150\n",
      "Epoch:  703/1000 Batch    1/8                     Loss: 0.570147\n",
      "Epoch:  704/1000 Batch    1/8                     Loss: 0.570145\n",
      "Epoch:  705/1000 Batch    1/8                     Loss: 0.570142\n",
      "Epoch:  706/1000 Batch    1/8                     Loss: 0.570140\n",
      "Epoch:  707/1000 Batch    1/8                     Loss: 0.570137\n",
      "Epoch:  708/1000 Batch    1/8                     Loss: 0.570134\n",
      "Epoch:  709/1000 Batch    1/8                     Loss: 0.570131\n",
      "Epoch:  710/1000 Batch    1/8                     Loss: 0.570128\n",
      "Epoch:  711/1000 Batch    1/8                     Loss: 0.570126\n",
      "Epoch:  712/1000 Batch    1/8                     Loss: 0.570123\n",
      "Epoch:  713/1000 Batch    1/8                     Loss: 0.570120\n",
      "Epoch:  714/1000 Batch    1/8                     Loss: 0.570117\n",
      "Epoch:  715/1000 Batch    1/8                     Loss: 0.570114\n",
      "Epoch:  716/1000 Batch    1/8                     Loss: 0.570110\n",
      "Epoch:  717/1000 Batch    1/8                     Loss: 0.570107\n",
      "Epoch:  718/1000 Batch    1/8                     Loss: 0.570104\n",
      "Epoch:  719/1000 Batch    1/8                     Loss: 0.570101\n",
      "Epoch:  720/1000 Batch    1/8                     Loss: 0.570098\n",
      "Epoch:  721/1000 Batch    1/8                     Loss: 0.570094\n",
      "Epoch:  722/1000 Batch    1/8                     Loss: 0.570091\n",
      "Epoch:  723/1000 Batch    1/8                     Loss: 0.570088\n",
      "Epoch:  724/1000 Batch    1/8                     Loss: 0.570084\n",
      "Epoch:  725/1000 Batch    1/8                     Loss: 0.570081\n",
      "Epoch:  726/1000 Batch    1/8                     Loss: 0.570077\n",
      "Epoch:  727/1000 Batch    1/8                     Loss: 0.570074\n",
      "Epoch:  728/1000 Batch    1/8                     Loss: 0.570070\n",
      "Epoch:  729/1000 Batch    1/8                     Loss: 0.570067\n",
      "Epoch:  730/1000 Batch    1/8                     Loss: 0.570063\n",
      "Epoch:  731/1000 Batch    1/8                     Loss: 0.570060\n",
      "Epoch:  732/1000 Batch    1/8                     Loss: 0.570056\n",
      "Epoch:  733/1000 Batch    1/8                     Loss: 0.570052\n",
      "Epoch:  734/1000 Batch    1/8                     Loss: 0.570049\n",
      "Epoch:  735/1000 Batch    1/8                     Loss: 0.570045\n",
      "Epoch:  736/1000 Batch    1/8                     Loss: 0.570041\n",
      "Epoch:  737/1000 Batch    1/8                     Loss: 0.570037\n",
      "Epoch:  738/1000 Batch    1/8                     Loss: 0.570034\n",
      "Epoch:  739/1000 Batch    1/8                     Loss: 0.570030\n",
      "Epoch:  740/1000 Batch    1/8                     Loss: 0.570026\n",
      "Epoch:  741/1000 Batch    1/8                     Loss: 0.570022\n",
      "Epoch:  742/1000 Batch    1/8                     Loss: 0.570018\n",
      "Epoch:  743/1000 Batch    1/8                     Loss: 0.570014\n",
      "Epoch:  744/1000 Batch    1/8                     Loss: 0.570010\n",
      "Epoch:  745/1000 Batch    1/8                     Loss: 0.570006\n",
      "Epoch:  746/1000 Batch    1/8                     Loss: 0.570002\n",
      "Epoch:  747/1000 Batch    1/8                     Loss: 0.569997\n",
      "Epoch:  748/1000 Batch    1/8                     Loss: 0.569993\n",
      "Epoch:  749/1000 Batch    1/8                     Loss: 0.569989\n",
      "Epoch:  750/1000 Batch    1/8                     Loss: 0.569984\n",
      "Epoch:  751/1000 Batch    1/8                     Loss: 0.569980\n",
      "Epoch:  752/1000 Batch    1/8                     Loss: 0.569975\n",
      "Epoch:  753/1000 Batch    1/8                     Loss: 0.569971\n",
      "Epoch:  754/1000 Batch    1/8                     Loss: 0.569966\n",
      "Epoch:  755/1000 Batch    1/8                     Loss: 0.569961\n",
      "Epoch:  756/1000 Batch    1/8                     Loss: 0.569956\n",
      "Epoch:  757/1000 Batch    1/8                     Loss: 0.569951\n",
      "Epoch:  758/1000 Batch    1/8                     Loss: 0.569945\n",
      "Epoch:  759/1000 Batch    1/8                     Loss: 0.569940\n",
      "Epoch:  760/1000 Batch    1/8                     Loss: 0.569934\n",
      "Epoch:  761/1000 Batch    1/8                     Loss: 0.569928\n",
      "Epoch:  762/1000 Batch    1/8                     Loss: 0.569921\n",
      "Epoch:  763/1000 Batch    1/8                     Loss: 0.569914\n",
      "Epoch:  764/1000 Batch    1/8                     Loss: 0.569906\n",
      "Epoch:  765/1000 Batch    1/8                     Loss: 0.569898\n",
      "Epoch:  766/1000 Batch    1/8                     Loss: 0.569889\n",
      "Epoch:  767/1000 Batch    1/8                     Loss: 0.569879\n",
      "Epoch:  768/1000 Batch    1/8                     Loss: 0.569868\n",
      "Epoch:  769/1000 Batch    1/8                     Loss: 0.569854\n",
      "Epoch:  770/1000 Batch    1/8                     Loss: 0.569838\n",
      "Epoch:  771/1000 Batch    1/8                     Loss: 0.569818\n",
      "Epoch:  772/1000 Batch    1/8                     Loss: 0.569794\n",
      "Epoch:  773/1000 Batch    1/8                     Loss: 0.569760\n",
      "Epoch:  774/1000 Batch    1/8                     Loss: 0.569714\n",
      "Epoch:  775/1000 Batch    1/8                     Loss: 0.569645\n",
      "Epoch:  776/1000 Batch    1/8                     Loss: 0.569533\n",
      "Epoch:  777/1000 Batch    1/8                     Loss: 0.569331\n",
      "Epoch:  778/1000 Batch    1/8                     Loss: 0.568934\n",
      "Epoch:  779/1000 Batch    1/8                     Loss: 0.568191\n",
      "Epoch:  780/1000 Batch    1/8                     Loss: 0.567376\n",
      "Epoch:  781/1000 Batch    1/8                     Loss: 0.567058\n",
      "Epoch:  782/1000 Batch    1/8                     Loss: 0.567009\n",
      "Epoch:  783/1000 Batch    1/8                     Loss: 0.567008\n",
      "Epoch:  784/1000 Batch    1/8                     Loss: 0.566976\n",
      "Epoch:  785/1000 Batch    1/8                     Loss: 0.566908\n",
      "Epoch:  786/1000 Batch    1/8                     Loss: 0.566838\n",
      "Epoch:  787/1000 Batch    1/8                     Loss: 0.566784\n",
      "Epoch:  788/1000 Batch    1/8                     Loss: 0.566742\n",
      "Epoch:  789/1000 Batch    1/8                     Loss: 0.566707\n",
      "Epoch:  790/1000 Batch    1/8                     Loss: 0.566673\n",
      "Epoch:  791/1000 Batch    1/8                     Loss: 0.566641\n",
      "Epoch:  792/1000 Batch    1/8                     Loss: 0.566611\n",
      "Epoch:  793/1000 Batch    1/8                     Loss: 0.566585\n",
      "Epoch:  794/1000 Batch    1/8                     Loss: 0.566560\n",
      "Epoch:  795/1000 Batch    1/8                     Loss: 0.566538\n",
      "Epoch:  796/1000 Batch    1/8                     Loss: 0.566517\n",
      "Epoch:  797/1000 Batch    1/8                     Loss: 0.566499\n",
      "Epoch:  798/1000 Batch    1/8                     Loss: 0.566481\n",
      "Epoch:  799/1000 Batch    1/8                     Loss: 0.566464\n",
      "Epoch:  800/1000 Batch    1/8                     Loss: 0.566449\n",
      "Epoch:  801/1000 Batch    1/8                     Loss: 0.566435\n",
      "Epoch:  802/1000 Batch    1/8                     Loss: 0.566422\n",
      "Epoch:  803/1000 Batch    1/8                     Loss: 0.566409\n",
      "Epoch:  804/1000 Batch    1/8                     Loss: 0.566397\n",
      "Epoch:  805/1000 Batch    1/8                     Loss: 0.566386\n",
      "Epoch:  806/1000 Batch    1/8                     Loss: 0.566376\n",
      "Epoch:  807/1000 Batch    1/8                     Loss: 0.566366\n",
      "Epoch:  808/1000 Batch    1/8                     Loss: 0.566357\n",
      "Epoch:  809/1000 Batch    1/8                     Loss: 0.566348\n",
      "Epoch:  810/1000 Batch    1/8                     Loss: 0.566339\n",
      "Epoch:  811/1000 Batch    1/8                     Loss: 0.566331\n",
      "Epoch:  812/1000 Batch    1/8                     Loss: 0.566324\n",
      "Epoch:  813/1000 Batch    1/8                     Loss: 0.566316\n",
      "Epoch:  814/1000 Batch    1/8                     Loss: 0.566310\n",
      "Epoch:  815/1000 Batch    1/8                     Loss: 0.566303\n",
      "Epoch:  816/1000 Batch    1/8                     Loss: 0.566296\n",
      "Epoch:  817/1000 Batch    1/8                     Loss: 0.566290\n",
      "Epoch:  818/1000 Batch    1/8                     Loss: 0.566284\n",
      "Epoch:  819/1000 Batch    1/8                     Loss: 0.566279\n",
      "Epoch:  820/1000 Batch    1/8                     Loss: 0.566273\n",
      "Epoch:  821/1000 Batch    1/8                     Loss: 0.566268\n",
      "Epoch:  822/1000 Batch    1/8                     Loss: 0.566263\n",
      "Epoch:  823/1000 Batch    1/8                     Loss: 0.566258\n",
      "Epoch:  824/1000 Batch    1/8                     Loss: 0.566253\n",
      "Epoch:  825/1000 Batch    1/8                     Loss: 0.566248\n",
      "Epoch:  826/1000 Batch    1/8                     Loss: 0.566244\n",
      "Epoch:  827/1000 Batch    1/8                     Loss: 0.566240\n",
      "Epoch:  828/1000 Batch    1/8                     Loss: 0.566235\n",
      "Epoch:  829/1000 Batch    1/8                     Loss: 0.566231\n",
      "Epoch:  830/1000 Batch    1/8                     Loss: 0.566227\n",
      "Epoch:  831/1000 Batch    1/8                     Loss: 0.566223\n",
      "Epoch:  832/1000 Batch    1/8                     Loss: 0.566219\n",
      "Epoch:  833/1000 Batch    1/8                     Loss: 0.566216\n",
      "Epoch:  834/1000 Batch    1/8                     Loss: 0.566212\n",
      "Epoch:  835/1000 Batch    1/8                     Loss: 0.566208\n",
      "Epoch:  836/1000 Batch    1/8                     Loss: 0.566205\n",
      "Epoch:  837/1000 Batch    1/8                     Loss: 0.566202\n",
      "Epoch:  838/1000 Batch    1/8                     Loss: 0.566198\n",
      "Epoch:  839/1000 Batch    1/8                     Loss: 0.566195\n",
      "Epoch:  840/1000 Batch    1/8                     Loss: 0.566192\n",
      "Epoch:  841/1000 Batch    1/8                     Loss: 0.566189\n",
      "Epoch:  842/1000 Batch    1/8                     Loss: 0.566186\n",
      "Epoch:  843/1000 Batch    1/8                     Loss: 0.566183\n",
      "Epoch:  844/1000 Batch    1/8                     Loss: 0.566180\n",
      "Epoch:  845/1000 Batch    1/8                     Loss: 0.566177\n",
      "Epoch:  846/1000 Batch    1/8                     Loss: 0.566174\n",
      "Epoch:  847/1000 Batch    1/8                     Loss: 0.566171\n",
      "Epoch:  848/1000 Batch    1/8                     Loss: 0.566169\n",
      "Epoch:  849/1000 Batch    1/8                     Loss: 0.566166\n",
      "Epoch:  850/1000 Batch    1/8                     Loss: 0.566163\n",
      "Epoch:  851/1000 Batch    1/8                     Loss: 0.566161\n",
      "Epoch:  852/1000 Batch    1/8                     Loss: 0.566158\n",
      "Epoch:  853/1000 Batch    1/8                     Loss: 0.566156\n",
      "Epoch:  854/1000 Batch    1/8                     Loss: 0.566153\n",
      "Epoch:  855/1000 Batch    1/8                     Loss: 0.566151\n",
      "Epoch:  856/1000 Batch    1/8                     Loss: 0.566148\n",
      "Epoch:  857/1000 Batch    1/8                     Loss: 0.566146\n",
      "Epoch:  858/1000 Batch    1/8                     Loss: 0.566144\n",
      "Epoch:  859/1000 Batch    1/8                     Loss: 0.566141\n",
      "Epoch:  860/1000 Batch    1/8                     Loss: 0.566139\n",
      "Epoch:  861/1000 Batch    1/8                     Loss: 0.566137\n",
      "Epoch:  862/1000 Batch    1/8                     Loss: 0.566135\n",
      "Epoch:  863/1000 Batch    1/8                     Loss: 0.566132\n",
      "Epoch:  864/1000 Batch    1/8                     Loss: 0.566130\n",
      "Epoch:  865/1000 Batch    1/8                     Loss: 0.566128\n",
      "Epoch:  866/1000 Batch    1/8                     Loss: 0.566126\n",
      "Epoch:  867/1000 Batch    1/8                     Loss: 0.566124\n",
      "Epoch:  868/1000 Batch    1/8                     Loss: 0.566122\n",
      "Epoch:  869/1000 Batch    1/8                     Loss: 0.566120\n",
      "Epoch:  870/1000 Batch    1/8                     Loss: 0.566118\n",
      "Epoch:  871/1000 Batch    1/8                     Loss: 0.566116\n",
      "Epoch:  872/1000 Batch    1/8                     Loss: 0.566114\n",
      "Epoch:  873/1000 Batch    1/8                     Loss: 0.566112\n",
      "Epoch:  874/1000 Batch    1/8                     Loss: 0.566110\n",
      "Epoch:  875/1000 Batch    1/8                     Loss: 0.566108\n",
      "Epoch:  876/1000 Batch    1/8                     Loss: 0.566106\n",
      "Epoch:  877/1000 Batch    1/8                     Loss: 0.566104\n",
      "Epoch:  878/1000 Batch    1/8                     Loss: 0.566102\n",
      "Epoch:  879/1000 Batch    1/8                     Loss: 0.566100\n",
      "Epoch:  880/1000 Batch    1/8                     Loss: 0.566098\n",
      "Epoch:  881/1000 Batch    1/8                     Loss: 0.566096\n",
      "Epoch:  882/1000 Batch    1/8                     Loss: 0.566094\n",
      "Epoch:  883/1000 Batch    1/8                     Loss: 0.566093\n",
      "Epoch:  884/1000 Batch    1/8                     Loss: 0.566091\n",
      "Epoch:  885/1000 Batch    1/8                     Loss: 0.566089\n",
      "Epoch:  886/1000 Batch    1/8                     Loss: 0.566087\n",
      "Epoch:  887/1000 Batch    1/8                     Loss: 0.566085\n",
      "Epoch:  888/1000 Batch    1/8                     Loss: 0.566084\n",
      "Epoch:  889/1000 Batch    1/8                     Loss: 0.566082\n",
      "Epoch:  890/1000 Batch    1/8                     Loss: 0.566080\n",
      "Epoch:  891/1000 Batch    1/8                     Loss: 0.566078\n",
      "Epoch:  892/1000 Batch    1/8                     Loss: 0.566077\n",
      "Epoch:  893/1000 Batch    1/8                     Loss: 0.566075\n",
      "Epoch:  894/1000 Batch    1/8                     Loss: 0.566073\n",
      "Epoch:  895/1000 Batch    1/8                     Loss: 0.566071\n",
      "Epoch:  896/1000 Batch    1/8                     Loss: 0.566070\n",
      "Epoch:  897/1000 Batch    1/8                     Loss: 0.566068\n",
      "Epoch:  898/1000 Batch    1/8                     Loss: 0.566066\n",
      "Epoch:  899/1000 Batch    1/8                     Loss: 0.566065\n",
      "Epoch:  900/1000 Batch    1/8                     Loss: 0.566063\n",
      "Epoch:  901/1000 Batch    1/8                     Loss: 0.566061\n",
      "Epoch:  902/1000 Batch    1/8                     Loss: 0.566059\n",
      "Epoch:  903/1000 Batch    1/8                     Loss: 0.566058\n",
      "Epoch:  904/1000 Batch    1/8                     Loss: 0.566056\n",
      "Epoch:  905/1000 Batch    1/8                     Loss: 0.566055\n",
      "Epoch:  906/1000 Batch    1/8                     Loss: 0.566053\n",
      "Epoch:  907/1000 Batch    1/8                     Loss: 0.566051\n",
      "Epoch:  908/1000 Batch    1/8                     Loss: 0.566049\n",
      "Epoch:  909/1000 Batch    1/8                     Loss: 0.566048\n",
      "Epoch:  910/1000 Batch    1/8                     Loss: 0.566046\n",
      "Epoch:  911/1000 Batch    1/8                     Loss: 0.566045\n",
      "Epoch:  912/1000 Batch    1/8                     Loss: 0.566043\n",
      "Epoch:  913/1000 Batch    1/8                     Loss: 0.566042\n",
      "Epoch:  914/1000 Batch    1/8                     Loss: 0.566039\n",
      "Epoch:  915/1000 Batch    1/8                     Loss: 0.566039\n",
      "Epoch:  916/1000 Batch    1/8                     Loss: 0.566036\n",
      "Epoch:  917/1000 Batch    1/8                     Loss: 0.566036\n",
      "Epoch:  918/1000 Batch    1/8                     Loss: 0.566033\n",
      "Epoch:  919/1000 Batch    1/8                     Loss: 0.566033\n",
      "Epoch:  920/1000 Batch    1/8                     Loss: 0.566029\n",
      "Epoch:  921/1000 Batch    1/8                     Loss: 0.566030\n",
      "Epoch:  922/1000 Batch    1/8                     Loss: 0.566025\n",
      "Epoch:  923/1000 Batch    1/8                     Loss: 0.566028\n",
      "Epoch:  924/1000 Batch    1/8                     Loss: 0.566021\n",
      "Epoch:  925/1000 Batch    1/8                     Loss: 0.566026\n",
      "Epoch:  926/1000 Batch    1/8                     Loss: 0.566017\n",
      "Epoch:  927/1000 Batch    1/8                     Loss: 0.566025\n",
      "Epoch:  928/1000 Batch    1/8                     Loss: 0.566012\n",
      "Epoch:  929/1000 Batch    1/8                     Loss: 0.566025\n",
      "Epoch:  930/1000 Batch    1/8                     Loss: 0.566006\n",
      "Epoch:  931/1000 Batch    1/8                     Loss: 0.566028\n",
      "Epoch:  932/1000 Batch    1/8                     Loss: 0.566000\n",
      "Epoch:  933/1000 Batch    1/8                     Loss: 0.566039\n",
      "Epoch:  934/1000 Batch    1/8                     Loss: 0.565994\n",
      "Epoch:  935/1000 Batch    1/8                     Loss: 0.566072\n",
      "Epoch:  936/1000 Batch    1/8                     Loss: 0.565989\n",
      "Epoch:  937/1000 Batch    1/8                     Loss: 0.566134\n",
      "Epoch:  938/1000 Batch    1/8                     Loss: 0.565984\n",
      "Epoch:  939/1000 Batch    1/8                     Loss: 0.566183\n",
      "Epoch:  940/1000 Batch    1/8                     Loss: 0.565983\n",
      "Epoch:  941/1000 Batch    1/8                     Loss: 0.566245\n",
      "Epoch:  942/1000 Batch    1/8                     Loss: 0.565978\n",
      "Epoch:  943/1000 Batch    1/8                     Loss: 0.566275\n",
      "Epoch:  944/1000 Batch    1/8                     Loss: 0.565980\n",
      "Epoch:  945/1000 Batch    1/8                     Loss: 0.566401\n",
      "Epoch:  946/1000 Batch    1/8                     Loss: 0.565961\n",
      "Epoch:  947/1000 Batch    1/8                     Loss: 0.566348\n",
      "Epoch:  948/1000 Batch    1/8                     Loss: 0.565949\n",
      "Epoch:  949/1000 Batch    1/8                     Loss: 0.566320\n",
      "Epoch:  950/1000 Batch    1/8                     Loss: 0.565916\n",
      "Epoch:  951/1000 Batch    1/8                     Loss: 0.566022\n",
      "Epoch:  952/1000 Batch    1/8                     Loss: 0.566533\n",
      "Epoch:  953/1000 Batch    1/8                     Loss: 0.566288\n",
      "Epoch:  954/1000 Batch    1/8                     Loss: 0.568285\n",
      "Epoch:  955/1000 Batch    1/8                     Loss: 0.566785\n",
      "Epoch:  956/1000 Batch    1/8                     Loss: 0.567228\n",
      "Epoch:  957/1000 Batch    1/8                     Loss: 0.566494\n",
      "Epoch:  958/1000 Batch    1/8                     Loss: 0.566306\n",
      "Epoch:  959/1000 Batch    1/8                     Loss: 0.566184\n",
      "Epoch:  960/1000 Batch    1/8                     Loss: 0.565998\n",
      "Epoch:  961/1000 Batch    1/8                     Loss: 0.565937\n",
      "Epoch:  962/1000 Batch    1/8                     Loss: 0.565933\n",
      "Epoch:  963/1000 Batch    1/8                     Loss: 0.565924\n",
      "Epoch:  964/1000 Batch    1/8                     Loss: 0.565943\n",
      "Epoch:  965/1000 Batch    1/8                     Loss: 0.565942\n",
      "Epoch:  966/1000 Batch    1/8                     Loss: 0.565961\n",
      "Epoch:  967/1000 Batch    1/8                     Loss: 0.565952\n",
      "Epoch:  968/1000 Batch    1/8                     Loss: 0.565969\n",
      "Epoch:  969/1000 Batch    1/8                     Loss: 0.565954\n",
      "Epoch:  970/1000 Batch    1/8                     Loss: 0.565972\n",
      "Epoch:  971/1000 Batch    1/8                     Loss: 0.565954\n",
      "Epoch:  972/1000 Batch    1/8                     Loss: 0.565973\n",
      "Epoch:  973/1000 Batch    1/8                     Loss: 0.565949\n",
      "Epoch:  974/1000 Batch    1/8                     Loss: 0.565970\n",
      "Epoch:  975/1000 Batch    1/8                     Loss: 0.565939\n",
      "Epoch:  976/1000 Batch    1/8                     Loss: 0.565960\n",
      "Epoch:  977/1000 Batch    1/8                     Loss: 0.565921\n",
      "Epoch:  978/1000 Batch    1/8                     Loss: 0.565949\n",
      "Epoch:  979/1000 Batch    1/8                     Loss: 0.565903\n",
      "Epoch:  980/1000 Batch    1/8                     Loss: 0.565970\n",
      "Epoch:  981/1000 Batch    1/8                     Loss: 0.565920\n",
      "Epoch:  982/1000 Batch    1/8                     Loss: 0.566242\n",
      "Epoch:  983/1000 Batch    1/8                     Loss: 0.566172\n",
      "Epoch:  984/1000 Batch    1/8                     Loss: 0.566647\n",
      "Epoch:  985/1000 Batch    1/8                     Loss: 0.566463\n",
      "Epoch:  986/1000 Batch    1/8                     Loss: 0.566343\n",
      "Epoch:  987/1000 Batch    1/8                     Loss: 0.566131\n",
      "Epoch:  988/1000 Batch    1/8                     Loss: 0.565971\n",
      "Epoch:  989/1000 Batch    1/8                     Loss: 0.565909\n",
      "Epoch:  990/1000 Batch    1/8                     Loss: 0.565899\n",
      "Epoch:  991/1000 Batch    1/8                     Loss: 0.565895\n",
      "Epoch:  992/1000 Batch    1/8                     Loss: 0.565903\n",
      "Epoch:  993/1000 Batch    1/8                     Loss: 0.565910\n",
      "Epoch:  994/1000 Batch    1/8                     Loss: 0.565918\n",
      "Epoch:  995/1000 Batch    1/8                     Loss: 0.565924\n",
      "Epoch:  996/1000 Batch    1/8                     Loss: 0.565928\n",
      "Epoch:  997/1000 Batch    1/8                     Loss: 0.565931\n",
      "Epoch:  998/1000 Batch    1/8                     Loss: 0.565933\n",
      "Epoch:  999/1000 Batch    1/8                     Loss: 0.565935\n",
      "Epoch: 1000/1000 Batch    1/8                     Loss: 0.565935\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 구현한 커스텀 데이터셋 클래스의 인스턴스 생성\n",
    "dataset = DiabetesDataset(xy)\n",
    "# DataLoader 클래스를 사용하여 데이터를 불러온 후, 모델에 입력하게 된다.\n",
    "data_loader = DataLoader(dataset, batch_size=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape : torch.Size([759, 8]) | Y shape : torch.Size([759, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = LogisticRegressionModel()\n",
    "xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "dataset = DiabetesDataset(xy)\n",
    "bce_loss = nn.BCELoss(reduction='mean')\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape : torch.Size([759, 8]) | Y shape : torch.Size([759, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def fit(model, optimizer, loss_func, data_loader, epochs=1):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for batch_index, samples in enumer\n",
    "        optimizer.zero_grad() # 1\n",
    "        y_pred = model(x_train) # 2\n",
    "        loss = loss_func(y_pred, y_train) #3\n",
    "        loss.backward() # 4\n",
    "        optimizer.step() # 5\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch : {i+1}/{epochs}, loss : {loss.data}')\n",
    "        \n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     for batch_idx, samples in enumerate(data_loader):\n",
    "#         x_train, y_train = samples\n",
    "#         y_pred = model(x_train)\n",
    "#         loss = bce_loss(y_pred, y_train)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if (batch_idx % 10 == 0):\n",
    "#             print(f'Epoch: {epoch+1:4d}/{epochs} Batch {batch_idx+1:4d}/{len(data_loader)} \\\n",
    "#                     Loss: {loss.item():4f}')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 퀴즈 (Normal)  \n",
    "이전의 노트북 파일을 참고해서 LogisticRegressionModel 클래스를 구현하세요.  \n",
    "1) 생성자 :  \n",
    "모델의 은닉층 수는 3층이고 은닉층마다 (8, 6, 4) 개의 뉴런을 가집니다.  \n",
    "마지막 레이어에는 시그모이드 모듈을 이용해 예측값을 계산하도록 만드세요.  \n",
    "2) forward :   \n",
    "최종적으로 확률 값을 예측하도록 레이어를 쌓아서 y를 반환하세요.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 퀴즈 (Normal)  \n",
    "1) 위 모델을 학습시키기 위해서는 어떤 손실함수를 선택해야할까요??  \n",
    "2) 위의 로지스틱회귀 클래스 모델을 조금 더 메모리 효율적으로 구현하려면 어떻게 해야할까요?  \n",
    "3) 위의 로지스틱 회귀 모델을 공책에 그려봅시다. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataloader를 활용한 학습  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 퀴즈 (Easy)  \n",
    "위 학습 반복문에서 enumerate를 사용했습니다. 그 이유가 무엇일까요?  "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Working': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "026aceb1435085fcef523649cdfc9385a4a55dbc5c65435142607853821fa50a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}