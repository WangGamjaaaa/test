{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 저장과 로드  \n",
    "여러분은 클라우드를 사용하면서 세션이 끊어지는 것을 한 번쯤은 경험해보셨을 것입니다.  \n",
    "이때, 만약 학습한 가중치를 저장하지 않는다면 몇 시간을 학습한 것이 날아갈 것입니다.   \n",
    "이번에는 학습 과정에서 모델을 저장하는 방법과, 학습 전에 모델을 불러오는 방법을 배우겠습니다.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quiz (Easy)  \n",
    "0) run_cnn2 파일을 만들어서 기존의 코드를 리팩터링 해봅시다.  \n",
    "1) 앞에서 배웠던 argparser를 이용해 config_path, save_path, pre_trained 인자를 추가하세요  \n",
    "2) 상위 폴더에 weights 폴더를 만드세요.   \n",
    "3) save_path의 default 값은 './weights'이고 config_path의 default는 './configs' 입니다.  \n",
    "4) pre_trained의 type은 bool이고 defaut 값은 False 입니다.  \n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%%writefile go.py\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description = 'quiz')\n",
    "parser.add_argument('-c','--config_path', type=str, default='configs/',help='config path')\n",
    "parser.add_argument('--save_path', type=str, default='weights/', help='save path')\n",
    "parser.add_argument('--pretrain', type=bool, default=False, help='pretrain or not')\n",
    "parser.add_argument('--model_name', type=str, default=\"CNN\", help='model name')\n",
    "\n",
    "## 1) 구현\n",
    "# 1. args 출력하기\n",
    "# 2. args 들 중 config_path를 통해 yaml 파일을 config변수에 할당.\n",
    "# 3. config출력하기\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args)\n",
    "\n",
    "\n",
    "\n",
    "with open(args.config_path) as f:\n",
    "    config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "\n",
    "print(config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting go.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "!python3 go.py -c 'configs/cnn.yaml'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(config_path='configs/cnn.yaml', model_name='CNN', pretrain=False, save_path='weights/')\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'epochs': 1, 'kernel_size': 2, 'stride': 2}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quiz (Easy)  \n",
    "모델을 로드하고 저장하는 부분을 구현하기 위해 train, test 코드를 수정해야 합니다.  \n",
    "아래에서 어떤 부분에 추가해야할까요??  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train(epoch, model, loss_func, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch+1} | Batch Status: {batch_index*len(x)}/{len(train_loader.dataset)} \\\n",
    "            ({100. * batch_index * batch_size / len(train_loader.dataset):.0f}% | Loss: {loss.item():.6f}')\n",
    "            \n",
    "def test(model, loss_func, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss += loss_func(y_pred, y).item()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        # torch.eq : Computes element-wise equality. return counts value\n",
    "        correct_count += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'=======================\\n Test set: Average loss: {test_loss:.4f}, Accuracy: {correct_count/len(test_loader.dataset):.3}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save, Load  \n",
    "모델의 저장과 로드는 torch.load_state_dict(), torch.load(), torch.save()를 활용합니다.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from models.cnn import CNN\n",
    "cnn = CNN(C=1,W=28,H=28,K=3,S=2)\n",
    "\n",
    "# state_dict는 모델의 모든 가중치를 반환한다.\n",
    "\n",
    "print(cnn.state_dict())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13\n",
      "6\n",
      "2\n",
      "OrderedDict([('conv1.weight', tensor([[[[-0.0959,  0.0448, -0.0365],\n",
      "          [ 0.1765, -0.1323,  0.2271],\n",
      "          [ 0.1100, -0.1851, -0.2927]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0091, -0.2706, -0.0501],\n",
      "          [ 0.2494, -0.1672,  0.1997],\n",
      "          [ 0.0156, -0.0465, -0.2946]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3318, -0.1790, -0.3124],\n",
      "          [ 0.2739, -0.2633,  0.2141],\n",
      "          [ 0.0663, -0.1285, -0.1256]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0034, -0.2547,  0.1879],\n",
      "          [-0.0933,  0.0309,  0.2450],\n",
      "          [-0.1583, -0.2097,  0.2522]]],\n",
      "\n",
      "\n",
      "        [[[-0.2095,  0.2651, -0.3029],\n",
      "          [ 0.2819, -0.1838, -0.2278],\n",
      "          [-0.0594, -0.0848, -0.1089]]],\n",
      "\n",
      "\n",
      "        [[[-0.2096, -0.3184, -0.2092],\n",
      "          [-0.0919,  0.3043, -0.2828],\n",
      "          [ 0.3160,  0.3102, -0.0383]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3063, -0.1473, -0.0669],\n",
      "          [-0.1923,  0.2627, -0.0993],\n",
      "          [ 0.2861, -0.0781, -0.1297]]],\n",
      "\n",
      "\n",
      "        [[[-0.3105, -0.2577,  0.0644],\n",
      "          [ 0.2340, -0.0420,  0.1735],\n",
      "          [ 0.0144,  0.1251,  0.2789]]],\n",
      "\n",
      "\n",
      "        [[[-0.0261, -0.0524, -0.1916],\n",
      "          [-0.1038,  0.1447, -0.2588],\n",
      "          [-0.1929,  0.1723, -0.2989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2859, -0.1053, -0.0532],\n",
      "          [ 0.0552, -0.1255, -0.3312],\n",
      "          [ 0.1642, -0.1440, -0.3278]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3262,  0.3111,  0.1883],\n",
      "          [-0.0298,  0.1201,  0.1432],\n",
      "          [-0.1063, -0.3301, -0.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1916, -0.1302, -0.0811],\n",
      "          [ 0.3058,  0.0196, -0.3156],\n",
      "          [ 0.0445, -0.0617,  0.3013]]],\n",
      "\n",
      "\n",
      "        [[[-0.1849, -0.0540, -0.1603],\n",
      "          [-0.1953,  0.3245,  0.1040],\n",
      "          [-0.2677,  0.1571,  0.2303]]],\n",
      "\n",
      "\n",
      "        [[[-0.1871, -0.2566, -0.1730],\n",
      "          [-0.2451, -0.0918,  0.1811],\n",
      "          [ 0.2423,  0.0711, -0.1540]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3135,  0.2709,  0.2418],\n",
      "          [ 0.3292,  0.2262, -0.0361],\n",
      "          [ 0.1557,  0.0577,  0.2196]]],\n",
      "\n",
      "\n",
      "        [[[-0.2512,  0.2922,  0.1430],\n",
      "          [ 0.0495, -0.0329, -0.2821],\n",
      "          [ 0.3124,  0.2134, -0.1048]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1219, -0.3083,  0.1127],\n",
      "          [ 0.0607, -0.0614, -0.1433],\n",
      "          [-0.0548,  0.2944,  0.0606]]],\n",
      "\n",
      "\n",
      "        [[[-0.1286, -0.1750, -0.0838],\n",
      "          [-0.0885,  0.1166,  0.3253],\n",
      "          [-0.2857, -0.0267,  0.3278]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0061, -0.2325,  0.0215],\n",
      "          [-0.3168,  0.1033, -0.1864],\n",
      "          [-0.1436,  0.0786,  0.2437]]],\n",
      "\n",
      "\n",
      "        [[[-0.2489,  0.0134, -0.2641],\n",
      "          [ 0.2693,  0.3244, -0.3039],\n",
      "          [-0.1968, -0.0696,  0.3263]]],\n",
      "\n",
      "\n",
      "        [[[-0.1892, -0.0516, -0.1213],\n",
      "          [-0.2940,  0.2869,  0.2214],\n",
      "          [ 0.2952,  0.2339,  0.2970]]],\n",
      "\n",
      "\n",
      "        [[[-0.2637, -0.1760,  0.2594],\n",
      "          [-0.0931, -0.2248,  0.2065],\n",
      "          [-0.2600,  0.0474,  0.0447]]],\n",
      "\n",
      "\n",
      "        [[[-0.2504,  0.0054, -0.0165],\n",
      "          [-0.2903,  0.2465,  0.2993],\n",
      "          [ 0.1316, -0.1140,  0.2535]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0447, -0.2667, -0.0688],\n",
      "          [-0.2260, -0.2094, -0.2710],\n",
      "          [ 0.1439,  0.2676, -0.1487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0660,  0.2413, -0.2206],\n",
      "          [ 0.0437, -0.1715,  0.2366],\n",
      "          [-0.0259,  0.2704, -0.0320]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0727, -0.3311,  0.1365],\n",
      "          [ 0.2778,  0.3294, -0.1895],\n",
      "          [-0.2039,  0.0920, -0.0829]]],\n",
      "\n",
      "\n",
      "        [[[-0.1011,  0.0808, -0.1429],\n",
      "          [ 0.2513, -0.3088,  0.1682],\n",
      "          [-0.1837, -0.2402,  0.1746]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3099, -0.0236, -0.1581],\n",
      "          [-0.2152,  0.2770, -0.2646],\n",
      "          [-0.0167,  0.0603, -0.1191]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0382,  0.2478,  0.1736],\n",
      "          [ 0.2414, -0.2486,  0.3187],\n",
      "          [-0.0075,  0.1617, -0.1189]]],\n",
      "\n",
      "\n",
      "        [[[-0.3013,  0.0044, -0.0693],\n",
      "          [ 0.0590,  0.1225,  0.2005],\n",
      "          [-0.2092, -0.2448, -0.2231]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2520,  0.2814,  0.1427],\n",
      "          [ 0.2431, -0.0032, -0.3174],\n",
      "          [ 0.2707,  0.0791, -0.1612]]],\n",
      "\n",
      "\n",
      "        [[[-0.2143,  0.0441, -0.3164],\n",
      "          [-0.0213, -0.0254,  0.2233],\n",
      "          [ 0.2256, -0.0176, -0.0208]]]])), ('conv1.bias', tensor([ 0.1619, -0.0507,  0.0797, -0.0772, -0.3001, -0.1042, -0.1097, -0.1568,\n",
      "         0.1985,  0.2023,  0.1124,  0.1721, -0.2413,  0.0385,  0.1652, -0.0194,\n",
      "        -0.1462, -0.1840,  0.0069,  0.0178,  0.2286,  0.1894, -0.0488, -0.0487,\n",
      "         0.0076, -0.2683, -0.1800, -0.0717,  0.1740, -0.1782, -0.1858, -0.2584])), ('bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.num_batches_tracked', tensor(0)), ('conv2.weight', tensor([[[[-0.0079,  0.0091, -0.0050],\n",
      "          [ 0.0280, -0.0146, -0.0095],\n",
      "          [ 0.0143, -0.0195, -0.0421]],\n",
      "\n",
      "         [[ 0.0044,  0.0328,  0.0425],\n",
      "          [-0.0325, -0.0026, -0.0299],\n",
      "          [-0.0134,  0.0139,  0.0276]],\n",
      "\n",
      "         [[-0.0282, -0.0517,  0.0104],\n",
      "          [-0.0386,  0.0270,  0.0215],\n",
      "          [ 0.0107,  0.0270, -0.0151]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0524,  0.0310,  0.0389],\n",
      "          [-0.0288, -0.0305,  0.0529],\n",
      "          [ 0.0390,  0.0460,  0.0484]],\n",
      "\n",
      "         [[-0.0219, -0.0208, -0.0146],\n",
      "          [-0.0055,  0.0224, -0.0530],\n",
      "          [ 0.0574, -0.0185, -0.0285]],\n",
      "\n",
      "         [[ 0.0275,  0.0083, -0.0549],\n",
      "          [ 0.0498, -0.0371, -0.0174],\n",
      "          [-0.0042,  0.0198,  0.0226]]],\n",
      "\n",
      "\n",
      "        [[[-0.0422, -0.0249, -0.0059],\n",
      "          [ 0.0568,  0.0158,  0.0113],\n",
      "          [-0.0527,  0.0217,  0.0104]],\n",
      "\n",
      "         [[ 0.0211, -0.0569, -0.0077],\n",
      "          [ 0.0200, -0.0363,  0.0439],\n",
      "          [-0.0265,  0.0264,  0.0027]],\n",
      "\n",
      "         [[-0.0064, -0.0057, -0.0206],\n",
      "          [-0.0256,  0.0565,  0.0054],\n",
      "          [ 0.0256,  0.0108,  0.0450]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0202,  0.0250, -0.0526],\n",
      "          [-0.0527, -0.0347,  0.0440],\n",
      "          [-0.0173,  0.0468,  0.0356]],\n",
      "\n",
      "         [[ 0.0352, -0.0569,  0.0055],\n",
      "          [-0.0255,  0.0040,  0.0187],\n",
      "          [ 0.0577,  0.0375, -0.0360]],\n",
      "\n",
      "         [[-0.0176, -0.0377, -0.0009],\n",
      "          [ 0.0488,  0.0207, -0.0538],\n",
      "          [ 0.0309, -0.0451, -0.0518]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0293, -0.0294,  0.0015],\n",
      "          [-0.0293,  0.0116,  0.0092],\n",
      "          [-0.0415,  0.0414, -0.0009]],\n",
      "\n",
      "         [[-0.0251,  0.0182, -0.0111],\n",
      "          [-0.0116, -0.0041,  0.0208],\n",
      "          [ 0.0518,  0.0098,  0.0257]],\n",
      "\n",
      "         [[-0.0178,  0.0160, -0.0516],\n",
      "          [ 0.0264, -0.0322,  0.0222],\n",
      "          [ 0.0428,  0.0496,  0.0272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0350, -0.0194, -0.0157],\n",
      "          [-0.0026, -0.0567,  0.0365],\n",
      "          [-0.0327, -0.0318, -0.0507]],\n",
      "\n",
      "         [[-0.0424,  0.0515,  0.0040],\n",
      "          [-0.0163,  0.0394,  0.0299],\n",
      "          [ 0.0274,  0.0056, -0.0352]],\n",
      "\n",
      "         [[ 0.0408, -0.0167, -0.0264],\n",
      "          [-0.0296, -0.0211,  0.0177],\n",
      "          [ 0.0036,  0.0065,  0.0198]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0233, -0.0197, -0.0299],\n",
      "          [ 0.0402, -0.0363, -0.0567],\n",
      "          [-0.0537,  0.0048,  0.0305]],\n",
      "\n",
      "         [[-0.0427,  0.0393,  0.0464],\n",
      "          [-0.0565, -0.0414,  0.0197],\n",
      "          [-0.0019, -0.0066, -0.0457]],\n",
      "\n",
      "         [[-0.0200, -0.0469, -0.0352],\n",
      "          [ 0.0401,  0.0369, -0.0256],\n",
      "          [ 0.0461,  0.0052,  0.0394]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0205,  0.0483,  0.0206],\n",
      "          [-0.0403,  0.0095, -0.0231],\n",
      "          [ 0.0563, -0.0179, -0.0275]],\n",
      "\n",
      "         [[ 0.0186,  0.0518,  0.0081],\n",
      "          [ 0.0180, -0.0122, -0.0225],\n",
      "          [ 0.0247,  0.0154,  0.0023]],\n",
      "\n",
      "         [[-0.0124,  0.0284, -0.0131],\n",
      "          [-0.0183, -0.0403,  0.0368],\n",
      "          [-0.0270,  0.0218, -0.0279]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0350, -0.0050, -0.0041],\n",
      "          [ 0.0410,  0.0062,  0.0223],\n",
      "          [-0.0028,  0.0528, -0.0542]],\n",
      "\n",
      "         [[-0.0077, -0.0351, -0.0008],\n",
      "          [ 0.0021, -0.0318, -0.0536],\n",
      "          [-0.0083,  0.0327,  0.0067]],\n",
      "\n",
      "         [[ 0.0498,  0.0203, -0.0523],\n",
      "          [-0.0394,  0.0175,  0.0129],\n",
      "          [ 0.0470,  0.0116, -0.0528]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0584, -0.0542, -0.0203],\n",
      "          [-0.0533,  0.0006, -0.0146],\n",
      "          [ 0.0537,  0.0511,  0.0423]],\n",
      "\n",
      "         [[-0.0140, -0.0043, -0.0523],\n",
      "          [ 0.0193,  0.0017, -0.0200],\n",
      "          [-0.0359, -0.0181,  0.0548]],\n",
      "\n",
      "         [[-0.0518, -0.0475, -0.0520],\n",
      "          [ 0.0247,  0.0364,  0.0056],\n",
      "          [ 0.0480, -0.0503, -0.0370]]],\n",
      "\n",
      "\n",
      "        [[[-0.0581, -0.0105,  0.0109],\n",
      "          [ 0.0123, -0.0430,  0.0517],\n",
      "          [ 0.0493,  0.0186, -0.0176]],\n",
      "\n",
      "         [[-0.0002,  0.0466,  0.0278],\n",
      "          [ 0.0062, -0.0138, -0.0407],\n",
      "          [-0.0102, -0.0442, -0.0015]],\n",
      "\n",
      "         [[ 0.0406, -0.0517, -0.0254],\n",
      "          [-0.0048, -0.0198,  0.0071],\n",
      "          [ 0.0228, -0.0568,  0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0374, -0.0287, -0.0468],\n",
      "          [-0.0151, -0.0017, -0.0570],\n",
      "          [ 0.0368,  0.0510,  0.0056]],\n",
      "\n",
      "         [[-0.0439,  0.0274, -0.0192],\n",
      "          [ 0.0147,  0.0392,  0.0438],\n",
      "          [ 0.0329,  0.0478,  0.0188]],\n",
      "\n",
      "         [[ 0.0321, -0.0353,  0.0583],\n",
      "          [-0.0436,  0.0384,  0.0134],\n",
      "          [ 0.0339, -0.0317, -0.0467]]]])), ('conv2.bias', tensor([ 0.0270, -0.0546, -0.0016, -0.0529,  0.0561, -0.0190, -0.0233, -0.0305,\n",
      "         0.0052, -0.0397, -0.0017,  0.0179,  0.0065, -0.0221,  0.0078,  0.0497,\n",
      "         0.0420, -0.0330,  0.0210,  0.0354, -0.0135, -0.0157, -0.0089, -0.0390,\n",
      "         0.0042,  0.0175, -0.0045, -0.0455,  0.0414,  0.0530,  0.0501, -0.0318,\n",
      "        -0.0084, -0.0044, -0.0509, -0.0557,  0.0210, -0.0033, -0.0079, -0.0270,\n",
      "        -0.0039, -0.0202,  0.0243,  0.0417,  0.0435, -0.0099,  0.0556,  0.0358,\n",
      "         0.0050, -0.0029, -0.0308,  0.0541, -0.0005, -0.0119,  0.0552, -0.0481,\n",
      "        -0.0063, -0.0146,  0.0135,  0.0344,  0.0409, -0.0342,  0.0430,  0.0146])), ('bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.num_batches_tracked', tensor(0)), ('conv3.weight', tensor([[[[ 0.0081,  0.0361,  0.0093],\n",
      "          [ 0.0030,  0.0392, -0.0235],\n",
      "          [-0.0322,  0.0253, -0.0091]],\n",
      "\n",
      "         [[-0.0411, -0.0234,  0.0157],\n",
      "          [-0.0125, -0.0333, -0.0129],\n",
      "          [ 0.0060, -0.0292,  0.0189]],\n",
      "\n",
      "         [[-0.0010, -0.0276,  0.0306],\n",
      "          [ 0.0290, -0.0228, -0.0411],\n",
      "          [ 0.0082,  0.0257, -0.0198]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0080,  0.0187, -0.0370],\n",
      "          [ 0.0033, -0.0121, -0.0138],\n",
      "          [ 0.0155, -0.0238,  0.0189]],\n",
      "\n",
      "         [[ 0.0152, -0.0162,  0.0157],\n",
      "          [-0.0311,  0.0212, -0.0080],\n",
      "          [-0.0177, -0.0224,  0.0032]],\n",
      "\n",
      "         [[-0.0309, -0.0006,  0.0165],\n",
      "          [-0.0014, -0.0152, -0.0184],\n",
      "          [ 0.0184,  0.0336,  0.0255]]],\n",
      "\n",
      "\n",
      "        [[[-0.0280, -0.0108, -0.0075],\n",
      "          [-0.0040,  0.0041, -0.0220],\n",
      "          [-0.0314, -0.0131,  0.0275]],\n",
      "\n",
      "         [[ 0.0089, -0.0340,  0.0082],\n",
      "          [-0.0012,  0.0306,  0.0088],\n",
      "          [-0.0400,  0.0043, -0.0005]],\n",
      "\n",
      "         [[-0.0005, -0.0021,  0.0102],\n",
      "          [-0.0057,  0.0195, -0.0054],\n",
      "          [ 0.0348,  0.0119, -0.0347]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0021,  0.0055,  0.0221],\n",
      "          [-0.0063, -0.0089, -0.0287],\n",
      "          [ 0.0393, -0.0339, -0.0022]],\n",
      "\n",
      "         [[ 0.0300, -0.0053,  0.0225],\n",
      "          [ 0.0268, -0.0025, -0.0103],\n",
      "          [-0.0102,  0.0348, -0.0413]],\n",
      "\n",
      "         [[ 0.0275,  0.0008,  0.0260],\n",
      "          [-0.0301,  0.0145,  0.0394],\n",
      "          [ 0.0406,  0.0138,  0.0079]]],\n",
      "\n",
      "\n",
      "        [[[-0.0121,  0.0106,  0.0401],\n",
      "          [ 0.0410, -0.0138, -0.0159],\n",
      "          [ 0.0116, -0.0193,  0.0348]],\n",
      "\n",
      "         [[-0.0259, -0.0212, -0.0145],\n",
      "          [ 0.0205, -0.0014, -0.0100],\n",
      "          [ 0.0192, -0.0284,  0.0175]],\n",
      "\n",
      "         [[ 0.0011,  0.0386,  0.0136],\n",
      "          [-0.0399,  0.0384, -0.0409],\n",
      "          [ 0.0065, -0.0137,  0.0116]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0115, -0.0079, -0.0221],\n",
      "          [-0.0269, -0.0207,  0.0338],\n",
      "          [ 0.0197,  0.0124, -0.0145]],\n",
      "\n",
      "         [[ 0.0220,  0.0387, -0.0113],\n",
      "          [ 0.0246,  0.0148, -0.0129],\n",
      "          [-0.0190,  0.0294,  0.0195]],\n",
      "\n",
      "         [[ 0.0234, -0.0265, -0.0043],\n",
      "          [-0.0345, -0.0382, -0.0383],\n",
      "          [-0.0323, -0.0106, -0.0252]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0004,  0.0387,  0.0174],\n",
      "          [ 0.0131,  0.0291,  0.0201],\n",
      "          [-0.0047,  0.0342,  0.0186]],\n",
      "\n",
      "         [[-0.0279, -0.0267,  0.0178],\n",
      "          [-0.0092,  0.0063,  0.0004],\n",
      "          [-0.0140,  0.0009, -0.0169]],\n",
      "\n",
      "         [[ 0.0308, -0.0194,  0.0051],\n",
      "          [ 0.0020,  0.0052,  0.0118],\n",
      "          [-0.0099, -0.0187, -0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0034,  0.0046, -0.0164],\n",
      "          [ 0.0186,  0.0100, -0.0111],\n",
      "          [ 0.0331,  0.0205,  0.0244]],\n",
      "\n",
      "         [[-0.0150, -0.0265, -0.0029],\n",
      "          [-0.0163,  0.0353, -0.0118],\n",
      "          [ 0.0247,  0.0071,  0.0177]],\n",
      "\n",
      "         [[ 0.0173, -0.0239,  0.0196],\n",
      "          [-0.0269, -0.0297, -0.0156],\n",
      "          [ 0.0224, -0.0055, -0.0088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0214, -0.0073,  0.0109],\n",
      "          [-0.0188, -0.0321,  0.0015],\n",
      "          [ 0.0323,  0.0095, -0.0247]],\n",
      "\n",
      "         [[ 0.0216, -0.0040,  0.0182],\n",
      "          [-0.0280,  0.0386,  0.0213],\n",
      "          [ 0.0329, -0.0169,  0.0251]],\n",
      "\n",
      "         [[ 0.0223,  0.0043, -0.0231],\n",
      "          [-0.0091, -0.0343,  0.0155],\n",
      "          [-0.0386,  0.0274, -0.0018]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0350, -0.0165,  0.0387],\n",
      "          [ 0.0397, -0.0307,  0.0389],\n",
      "          [ 0.0236, -0.0282,  0.0107]],\n",
      "\n",
      "         [[ 0.0039, -0.0009,  0.0034],\n",
      "          [ 0.0206,  0.0160,  0.0405],\n",
      "          [ 0.0306, -0.0306, -0.0053]],\n",
      "\n",
      "         [[-0.0343,  0.0093, -0.0202],\n",
      "          [ 0.0254, -0.0257, -0.0010],\n",
      "          [ 0.0149, -0.0134,  0.0134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0344,  0.0013,  0.0089],\n",
      "          [ 0.0382,  0.0012, -0.0283],\n",
      "          [ 0.0156, -0.0367,  0.0292]],\n",
      "\n",
      "         [[-0.0039,  0.0173,  0.0123],\n",
      "          [-0.0012,  0.0152,  0.0155],\n",
      "          [ 0.0086, -0.0260, -0.0311]],\n",
      "\n",
      "         [[ 0.0076, -0.0107, -0.0283],\n",
      "          [-0.0192,  0.0285, -0.0023],\n",
      "          [ 0.0255,  0.0044, -0.0003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0323,  0.0110, -0.0070],\n",
      "          [ 0.0230, -0.0262, -0.0249],\n",
      "          [-0.0132, -0.0359,  0.0145]],\n",
      "\n",
      "         [[ 0.0378, -0.0343,  0.0219],\n",
      "          [ 0.0307,  0.0290, -0.0105],\n",
      "          [ 0.0313,  0.0101,  0.0269]],\n",
      "\n",
      "         [[-0.0072, -0.0241, -0.0216],\n",
      "          [ 0.0273,  0.0296, -0.0227],\n",
      "          [-0.0080, -0.0158, -0.0137]]]])), ('conv3.bias', tensor([-3.8003e-02, -3.5590e-02, -1.1211e-02, -3.5394e-02,  3.3375e-03,\n",
      "        -1.3622e-03, -2.4372e-02, -3.6629e-02, -1.5384e-02,  2.7528e-02,\n",
      "         2.5458e-02,  1.5739e-02,  4.0704e-02, -8.2800e-03,  2.5581e-02,\n",
      "         3.2744e-02,  2.2969e-02,  1.2250e-02, -1.7034e-02,  2.6654e-02,\n",
      "         2.9882e-02,  1.1964e-02, -1.9832e-02, -2.8752e-02, -3.9955e-04,\n",
      "         9.1626e-03,  2.9598e-02, -1.0738e-02,  1.7469e-02, -3.4964e-02,\n",
      "         4.1240e-03, -2.9356e-02, -2.8257e-02, -8.9920e-03,  4.5747e-06,\n",
      "        -2.0731e-02, -3.3638e-02,  7.0661e-03, -1.9306e-03, -2.8417e-02,\n",
      "         3.6456e-03,  3.0014e-03, -1.2079e-02, -4.1288e-02,  4.1602e-02,\n",
      "         2.9786e-03,  3.5738e-02,  3.2052e-02, -3.4453e-02,  2.3136e-02,\n",
      "         1.9737e-02, -3.5449e-02,  4.1633e-02,  3.9429e-02,  2.5233e-02,\n",
      "         1.0922e-02, -3.1948e-02, -1.3774e-02, -3.1624e-03, -8.0752e-04,\n",
      "        -8.8996e-03,  4.1385e-02,  2.8535e-02,  3.0786e-02, -3.9534e-02,\n",
      "         6.3524e-03, -1.4876e-02,  3.0639e-02,  2.4515e-02, -2.0421e-02,\n",
      "        -4.0155e-03,  4.1066e-02, -4.1290e-02, -2.1873e-02, -3.9309e-02,\n",
      "         1.1634e-02, -2.8207e-02,  3.3627e-02, -2.5918e-02, -2.7584e-02,\n",
      "         6.8639e-03,  6.8055e-03,  3.8547e-02, -4.0474e-02,  2.4212e-02,\n",
      "        -2.5427e-02, -1.5559e-02,  3.0061e-02,  1.8499e-02, -2.2650e-02,\n",
      "        -1.4869e-02,  2.0439e-02, -1.1114e-02, -2.4467e-03,  1.6203e-03,\n",
      "        -3.7411e-02,  3.3345e-02, -4.0147e-02,  3.7086e-02, -2.4258e-02,\n",
      "         2.8345e-02, -3.6175e-02,  3.9218e-02, -1.8647e-02,  1.3356e-02,\n",
      "         2.2568e-02, -5.4044e-04, -1.6181e-02,  3.3570e-02,  3.5249e-02,\n",
      "        -1.7466e-02,  3.5741e-02, -7.0929e-03,  1.7032e-02,  1.2275e-02,\n",
      "        -4.0142e-02, -2.5423e-02, -3.4900e-02,  3.6258e-02,  4.4880e-04,\n",
      "        -3.4339e-02, -2.0686e-04,  2.4380e-02, -7.1419e-03,  4.0234e-02,\n",
      "         1.0651e-02,  4.1074e-02, -1.0934e-02])), ('bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn3.num_batches_tracked', tensor(0)), ('fc.weight', tensor([[ 2.7223e-03,  4.1931e-02,  4.3572e-02,  ...,  3.5319e-02,\n",
      "          3.3003e-02, -1.9724e-02],\n",
      "        [-3.4233e-02, -2.4059e-03,  1.6292e-02,  ..., -1.0653e-02,\n",
      "         -8.5913e-03, -3.8840e-02],\n",
      "        [ 2.4963e-02,  4.4485e-04,  2.1897e-02,  ..., -3.2418e-02,\n",
      "         -3.0874e-02,  5.8595e-04],\n",
      "        ...,\n",
      "        [-1.2191e-02, -3.5351e-06, -1.0361e-04,  ..., -4.1989e-02,\n",
      "         -1.5973e-02, -2.3054e-02],\n",
      "        [ 4.3683e-02,  4.0255e-02,  3.2931e-02,  ...,  2.3270e-02,\n",
      "          2.1964e-02,  1.6362e-02],\n",
      "        [-1.4694e-02, -5.1524e-03, -4.3552e-02,  ..., -2.1968e-02,\n",
      "         -2.4813e-02, -1.6959e-02]])), ('fc.bias', tensor([ 0.0108,  0.0023, -0.0432, -0.0267,  0.0412,  0.0013,  0.0438,  0.0009,\n",
      "         0.0041,  0.0029]))])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "%%writefile go.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from models.cnn import CNN\n",
    "from dataset.MNIST_LOADER import make_loader\n",
    "import argparse\n",
    "import yaml\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description = 'quiz')\n",
    "parser.add_argument('-c','--config_path', type=str, default='configs/',help='config path')\n",
    "parser.add_argument('--save_path', type=str, default='weights/', help='save path')\n",
    "parser.add_argument('--pretrain', type=bool, default=False, help='pretrain or not')\n",
    "parser.add_argument('--model_name', type=str, default=\"CNN\", help='model name')\n",
    "\n",
    "## 1) 구현\n",
    "# 1. args 출력하기\n",
    "# 2. args 들 중 config_path를 통해 yaml 파일을 config변수에 할당.\n",
    "# 3. config출력하기\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "train_loader, vaild_loader, test_loader, shape = make_loader(16)\n",
    "C = shape[0]\n",
    "W = shape[1]\n",
    "H = shape[2]\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "cnn = CNN(C=C, W=W, H=H, K=3, S=2) \n",
    "cnn = cnn.to(device)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# with 구문으로 파일을 불러옵니다.\n",
    "\n",
    "with open(args.config_path) as f:\n",
    "    config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "    print(type(config))\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = config['batch_size']\n",
    "learning_rate = config['learning_rate']\n",
    "epochs = config['epochs']\n",
    "kernel_size = config['kernel_size']\n",
    "stride = config['stride']\n",
    "\n",
    "\n",
    "with open(args.config_path) as f:\n",
    "    config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "\n",
    "print(config)\n",
    "\n",
    "pre_trained = args.pretrain\n",
    "save_path = args.save_path\n",
    "model_name = args.model_name\n",
    "model = cnn\n",
    "\n",
    "if pre_trained:\n",
    "    model_dict = torch.load(save_path+model_name)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "writer = SummaryWriter('runs/cnn/')\n",
    "\n",
    "\n",
    "def train(epoch, model, loss_func, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"train/loss\", loss, epoch*batch_size + batch_index)\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch+1} | Batch Status: {batch_index*len(x)}/{len(train_loader.dataset)} \\\n",
    "            ({100. * batch_index * batch_size / len(train_loader.dataset):.0f}% | Loss: {loss.item():.6f}')\n",
    "            torch.save(model.state_dict(), save_path + model_name+str(epoch))\n",
    "            \n",
    "\n",
    "def test(model, loss_func, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss += loss_func(y_pred, y).item()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        # torch.eq : Computes element-wise equality. return counts value\n",
    "        correct_count += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'=======================\\n Test set: Average loss: {test_loss:.4f}, Accuracy: {correct_count/len(test_loader.dataset):.3}')\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(epoch, cnn, ce_loss, train_loader, optimizer)\n",
    "\n",
    "\n",
    "test(cnn, ce_loss, test_loader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting go.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "!python3 go.py -c 'configs/cnn.yaml'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "channel: 1, width: 28, height: 28\n",
      "13\n",
      "6\n",
      "2\n",
      "<class 'dict'>\n",
      "{'batch_size': 16, 'learning_rate': 0.001, 'epochs': 1, 'kernel_size': 2, 'stride': 2}\n",
      "2021-11-19 17:23:36.801076: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-19 17:23:36.801884: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/hchang/Working/Python3/Pytorch-Master/Practice/models/cnn.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "Train Epoch: 1 | Batch Status: 0/60000             (0% | Loss: 2.404390\n",
      "Train Epoch: 1 | Batch Status: 1600/60000             (3% | Loss: 1.469152\n",
      "Train Epoch: 1 | Batch Status: 3200/60000             (5% | Loss: 1.192706\n",
      "Train Epoch: 1 | Batch Status: 4800/60000             (8% | Loss: 1.292445\n",
      "Train Epoch: 1 | Batch Status: 6400/60000             (11% | Loss: 1.463641\n",
      "Train Epoch: 1 | Batch Status: 8000/60000             (13% | Loss: 1.285347\n",
      "Train Epoch: 1 | Batch Status: 9600/60000             (16% | Loss: 1.031442\n",
      "Train Epoch: 1 | Batch Status: 11200/60000             (19% | Loss: 1.609992\n",
      "Train Epoch: 1 | Batch Status: 12800/60000             (21% | Loss: 1.596382\n",
      "Train Epoch: 1 | Batch Status: 14400/60000             (24% | Loss: 1.080699\n",
      "Train Epoch: 1 | Batch Status: 16000/60000             (27% | Loss: 1.012189\n",
      "Train Epoch: 1 | Batch Status: 17600/60000             (29% | Loss: 1.328432\n",
      "Train Epoch: 1 | Batch Status: 19200/60000             (32% | Loss: 1.194558\n",
      "Train Epoch: 1 | Batch Status: 20800/60000             (35% | Loss: 1.041906\n",
      "Train Epoch: 1 | Batch Status: 22400/60000             (37% | Loss: 1.361665\n",
      "Train Epoch: 1 | Batch Status: 24000/60000             (40% | Loss: 0.868166\n",
      "Train Epoch: 1 | Batch Status: 25600/60000             (43% | Loss: 1.152666\n",
      "Train Epoch: 1 | Batch Status: 27200/60000             (45% | Loss: 0.866255\n",
      "Train Epoch: 1 | Batch Status: 28800/60000             (48% | Loss: 1.441740\n",
      "Train Epoch: 1 | Batch Status: 30400/60000             (51% | Loss: 1.186533\n",
      "Train Epoch: 1 | Batch Status: 32000/60000             (53% | Loss: 0.865827\n",
      "Train Epoch: 1 | Batch Status: 33600/60000             (56% | Loss: 1.032442\n",
      "Train Epoch: 1 | Batch Status: 35200/60000             (59% | Loss: 0.867246\n",
      "Train Epoch: 1 | Batch Status: 36800/60000             (61% | Loss: 1.120993\n",
      "Train Epoch: 1 | Batch Status: 38400/60000             (64% | Loss: 1.008160\n",
      "Train Epoch: 1 | Batch Status: 40000/60000             (67% | Loss: 1.527202\n",
      "Train Epoch: 1 | Batch Status: 41600/60000             (69% | Loss: 1.016186\n",
      "Train Epoch: 1 | Batch Status: 43200/60000             (72% | Loss: 1.442876\n",
      "Train Epoch: 1 | Batch Status: 44800/60000             (75% | Loss: 0.866906\n",
      "Train Epoch: 1 | Batch Status: 46400/60000             (77% | Loss: 1.565768\n",
      "Train Epoch: 1 | Batch Status: 48000/60000             (80% | Loss: 1.076448\n",
      "Train Epoch: 1 | Batch Status: 49600/60000             (83% | Loss: 1.009270\n",
      "Train Epoch: 1 | Batch Status: 51200/60000             (85% | Loss: 1.440040\n",
      "Train Epoch: 1 | Batch Status: 52800/60000             (88% | Loss: 1.152834\n",
      "Train Epoch: 1 | Batch Status: 54400/60000             (91% | Loss: 0.750105\n",
      "Train Epoch: 1 | Batch Status: 56000/60000             (93% | Loss: 1.583861\n",
      "Train Epoch: 1 | Batch Status: 57600/60000             (96% | Loss: 1.284516\n",
      "Train Epoch: 1 | Batch Status: 59200/60000             (99% | Loss: 1.016389\n",
      "OrderedDict([('conv1.weight', tensor([[[[-0.1586, -0.0361,  0.1204],\n",
      "          [-0.2957, -0.1089, -0.2215],\n",
      "          [ 0.2352,  0.0517, -0.0465]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1162, -0.3263,  0.0547],\n",
      "          [-0.3616,  0.0179, -0.2491],\n",
      "          [ 0.0045,  0.1573,  0.2858]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0608, -0.2328, -0.2566],\n",
      "          [-0.1697, -0.0942,  0.3177],\n",
      "          [-0.1592,  0.2068, -0.0158]]],\n",
      "\n",
      "\n",
      "        [[[-0.1844, -0.1111,  0.2700],\n",
      "          [-0.1374, -0.1277, -0.3079],\n",
      "          [-0.2308,  0.1155, -0.4012]]],\n",
      "\n",
      "\n",
      "        [[[-0.0814,  0.1293, -0.1158],\n",
      "          [ 0.0789, -0.3334, -0.1689],\n",
      "          [ 0.0830,  0.0736,  0.3189]]],\n",
      "\n",
      "\n",
      "        [[[-0.1596, -0.1555, -0.1425],\n",
      "          [ 0.0984, -0.1787,  0.2597],\n",
      "          [-0.3302, -0.1918,  0.1900]]],\n",
      "\n",
      "\n",
      "        [[[-0.1641, -0.0113,  0.3091],\n",
      "          [-0.2527, -0.0548, -0.0650],\n",
      "          [-0.3674,  0.2007, -0.0896]]],\n",
      "\n",
      "\n",
      "        [[[-0.2175, -0.0495,  0.0068],\n",
      "          [-0.0765,  0.2914,  0.1049],\n",
      "          [ 0.2802, -0.0789, -0.1632]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0413, -0.3124, -0.0104],\n",
      "          [-0.2148,  0.0057,  0.1605],\n",
      "          [-0.2301,  0.0952,  0.0089]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2817,  0.1749,  0.1517],\n",
      "          [-0.2388, -0.2075, -0.0233],\n",
      "          [-0.1351,  0.0971, -0.2140]]],\n",
      "\n",
      "\n",
      "        [[[-0.2957, -0.1628, -0.1938],\n",
      "          [ 0.0130, -0.1314,  0.0171],\n",
      "          [ 0.2511,  0.1374,  0.0501]]],\n",
      "\n",
      "\n",
      "        [[[-0.0553,  0.0297,  0.1961],\n",
      "          [-0.1473, -0.3727,  0.1699],\n",
      "          [ 0.3032, -0.1621, -0.1442]]],\n",
      "\n",
      "\n",
      "        [[[-0.1667, -0.2451, -0.1899],\n",
      "          [ 0.3793,  0.2175, -0.0372],\n",
      "          [-0.3103,  0.0784,  0.1547]]],\n",
      "\n",
      "\n",
      "        [[[-0.2457, -0.0796,  0.0436],\n",
      "          [-0.3212,  0.0138,  0.3216],\n",
      "          [ 0.0222, -0.2338,  0.1295]]],\n",
      "\n",
      "\n",
      "        [[[-0.2637,  0.2817, -0.3027],\n",
      "          [ 0.3009, -0.0236,  0.0601],\n",
      "          [ 0.2645, -0.2076,  0.3919]]],\n",
      "\n",
      "\n",
      "        [[[-0.1657,  0.2552, -0.1508],\n",
      "          [ 0.0550,  0.0499, -0.1469],\n",
      "          [-0.1682,  0.3026, -0.1175]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2427, -0.1433, -0.2236],\n",
      "          [ 0.2280,  0.1200, -0.3063],\n",
      "          [ 0.1455, -0.0393, -0.1085]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1544,  0.2552, -0.1691],\n",
      "          [ 0.0869, -0.1736, -0.1953],\n",
      "          [ 0.1615, -0.3988,  0.0735]]],\n",
      "\n",
      "\n",
      "        [[[-0.0863,  0.2438,  0.2371],\n",
      "          [ 0.3687,  0.3458, -0.1255],\n",
      "          [ 0.1319, -0.2656,  0.2741]]],\n",
      "\n",
      "\n",
      "        [[[-0.1340,  0.2723,  0.1560],\n",
      "          [-0.1385,  0.2534, -0.1017],\n",
      "          [-0.3302, -0.2974, -0.2861]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1071,  0.3169,  0.1300],\n",
      "          [-0.0240, -0.3225,  0.2512],\n",
      "          [-0.3052,  0.0601, -0.2447]]],\n",
      "\n",
      "\n",
      "        [[[-0.1921, -0.0832,  0.2368],\n",
      "          [-0.2620,  0.2633, -0.1115],\n",
      "          [ 0.3041,  0.3428,  0.3368]]],\n",
      "\n",
      "\n",
      "        [[[-0.0692, -0.0992, -0.0241],\n",
      "          [ 0.0987, -0.1235, -0.2849],\n",
      "          [ 0.1023,  0.2906, -0.0063]]],\n",
      "\n",
      "\n",
      "        [[[-0.0619, -0.2903, -0.1243],\n",
      "          [-0.1291,  0.2125, -0.0644],\n",
      "          [ 0.2375,  0.3100, -0.0520]]],\n",
      "\n",
      "\n",
      "        [[[-0.0018, -0.0482, -0.1092],\n",
      "          [-0.0510,  0.0727,  0.3467],\n",
      "          [ 0.2610,  0.3321,  0.2381]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0990, -0.3346,  0.1823],\n",
      "          [-0.1666,  0.1355, -0.3687],\n",
      "          [ 0.0956,  0.0724,  0.0225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0380,  0.0324, -0.1514],\n",
      "          [ 0.2307,  0.3437,  0.2122],\n",
      "          [-0.2872, -0.3009, -0.0610]]],\n",
      "\n",
      "\n",
      "        [[[-0.3113, -0.1450, -0.0914],\n",
      "          [ 0.2843,  0.0694, -0.3843],\n",
      "          [ 0.2238,  0.1168, -0.1275]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0904, -0.1436, -0.1736],\n",
      "          [-0.0008, -0.1253,  0.0622],\n",
      "          [-0.3371,  0.0680,  0.1513]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1654,  0.0199,  0.0484],\n",
      "          [ 0.1825,  0.2974, -0.0475],\n",
      "          [-0.3770,  0.1452, -0.1930]]],\n",
      "\n",
      "\n",
      "        [[[-0.1559, -0.0076,  0.1659],\n",
      "          [-0.0578, -0.2704, -0.1537],\n",
      "          [ 0.1396,  0.0540, -0.1965]]],\n",
      "\n",
      "\n",
      "        [[[-0.3150,  0.2192,  0.1691],\n",
      "          [-0.3291, -0.2867,  0.0636],\n",
      "          [-0.2411,  0.2753,  0.1461]]]])), ('conv1.bias', tensor([-0.3428,  0.2970, -0.3297,  0.0277, -0.1150, -0.0761,  0.1222,  0.2416,\n",
      "        -0.1376,  0.0465, -0.3344,  0.2128, -0.0726,  0.1723, -0.0313, -0.4321,\n",
      "        -0.2348,  0.0580, -0.2491,  0.3084, -0.0742, -0.2836, -0.0962,  0.3128,\n",
      "        -0.1392, -0.0253,  0.3618,  0.0876, -0.1857,  0.0767, -0.2547, -0.2581])), ('bn1.weight', tensor([1.0223, 1.1028, 1.1745, 0.9603, 0.9425, 1.0420, 0.8517, 1.0158, 1.0339,\n",
      "        1.0983, 0.9413, 1.2547, 1.1190, 1.0022, 0.7549, 0.8598, 1.0544, 0.9925,\n",
      "        0.7991, 1.2359, 0.9076, 0.8846, 1.1159, 0.8576, 0.8518, 0.9166, 1.0554,\n",
      "        1.1550, 1.1316, 0.8494, 1.1400, 0.9567])), ('bn1.bias', tensor([-0.0342, -0.0354,  0.0224, -0.0783, -0.1833, -0.0739, -0.1120, -0.1643,\n",
      "        -0.0289,  0.0391, -0.0295,  0.1064, -0.0593, -0.1109, -0.1228, -0.2420,\n",
      "        -0.0776, -0.0863, -0.1895,  0.0741, -0.1109, -0.1416,  0.0432, -0.0553,\n",
      "        -0.0350, -0.0815, -0.1640,  0.0313,  0.0448, -0.0647,  0.0458, -0.0585])), ('bn1.running_mean', tensor([-0.4157,  0.2471, -0.3828, -0.1440, -0.1190, -0.1717,  0.0465,  0.2504,\n",
      "        -0.2102,  0.0307, -0.3823,  0.1843, -0.0903,  0.1191,  0.0432, -0.4425,\n",
      "        -0.2474,  0.0298, -0.0773,  0.2120, -0.0791, -0.1579, -0.1129,  0.3177,\n",
      "         0.0181, -0.0651,  0.3585,  0.0334, -0.2521,  0.1191, -0.3301, -0.3056])), ('bn1.running_var', tensor([0.0227, 0.0262, 0.0219, 0.0939, 0.0091, 0.0434, 0.0361, 0.0090, 0.0281,\n",
      "        0.0172, 0.0293, 0.0105, 0.0114, 0.0342, 0.0286, 0.0040, 0.0317, 0.0252,\n",
      "        0.1009, 0.0516, 0.0214, 0.0847, 0.0114, 0.0214, 0.0990, 0.0096, 0.0117,\n",
      "        0.0314, 0.0224, 0.0193, 0.0226, 0.0427])), ('bn1.num_batches_tracked', tensor(3750)), ('conv2.weight', tensor([[[[-0.0170, -0.0449, -0.1280],\n",
      "          [-0.0137, -0.0098, -0.0177],\n",
      "          [ 0.0849,  0.1219,  0.0439]],\n",
      "\n",
      "         [[-0.0714,  0.0229,  0.0323],\n",
      "          [-0.0595, -0.0759, -0.1478],\n",
      "          [ 0.0466,  0.0419, -0.0113]],\n",
      "\n",
      "         [[-0.0554,  0.1076, -0.0554],\n",
      "          [-0.0706, -0.1607, -0.0870],\n",
      "          [-0.0930, -0.1224, -0.1826]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0534, -0.0158,  0.0555],\n",
      "          [ 0.0393, -0.0003,  0.0803],\n",
      "          [-0.0671, -0.0252, -0.0740]],\n",
      "\n",
      "         [[-0.0283, -0.0501, -0.1008],\n",
      "          [ 0.1480,  0.0825,  0.0073],\n",
      "          [-0.0024,  0.0533,  0.1486]],\n",
      "\n",
      "         [[-0.0298,  0.0457,  0.0521],\n",
      "          [-0.1103,  0.0509, -0.0259],\n",
      "          [ 0.0400,  0.0252,  0.0692]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0178,  0.0371, -0.0041],\n",
      "          [-0.0076,  0.0389,  0.0527],\n",
      "          [-0.0035,  0.0418, -0.0154]],\n",
      "\n",
      "         [[-0.0621, -0.0490,  0.0582],\n",
      "          [ 0.0587,  0.0431,  0.0837],\n",
      "          [-0.0044,  0.1303,  0.1036]],\n",
      "\n",
      "         [[-0.0650, -0.0227, -0.0707],\n",
      "          [ 0.1008,  0.0794,  0.0760],\n",
      "          [ 0.0825,  0.1208,  0.0867]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0408, -0.0458,  0.0522],\n",
      "          [ 0.0418,  0.0239, -0.1111],\n",
      "          [-0.1026, -0.0748,  0.0975]],\n",
      "\n",
      "         [[ 0.0462,  0.1385, -0.0080],\n",
      "          [ 0.0583, -0.0021, -0.0570],\n",
      "          [-0.0463, -0.0159, -0.0042]],\n",
      "\n",
      "         [[ 0.0722, -0.0402, -0.0492],\n",
      "          [ 0.0845,  0.0083, -0.0569],\n",
      "          [ 0.0286,  0.0302, -0.0516]]],\n",
      "\n",
      "\n",
      "        [[[-0.0446, -0.0224, -0.0112],\n",
      "          [ 0.0867,  0.0766, -0.0629],\n",
      "          [ 0.0424, -0.0184, -0.0860]],\n",
      "\n",
      "         [[-0.1032, -0.0777, -0.0863],\n",
      "          [-0.0097, -0.0441, -0.1092],\n",
      "          [ 0.0859,  0.1203, -0.0566]],\n",
      "\n",
      "         [[-0.0073, -0.0826, -0.0456],\n",
      "          [ 0.0034, -0.0076, -0.0234],\n",
      "          [-0.0069,  0.0481,  0.0323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0361, -0.0859,  0.0681],\n",
      "          [-0.0009, -0.0577,  0.0066],\n",
      "          [-0.0151,  0.0028,  0.0516]],\n",
      "\n",
      "         [[ 0.0692,  0.0039, -0.0358],\n",
      "          [ 0.0902, -0.0369, -0.0500],\n",
      "          [ 0.0351, -0.1104, -0.1035]],\n",
      "\n",
      "         [[-0.0076, -0.0697,  0.0344],\n",
      "          [ 0.0537, -0.0078,  0.1130],\n",
      "          [ 0.1146,  0.1521,  0.1818]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0011, -0.0542, -0.0492],\n",
      "          [ 0.0022, -0.0387, -0.0192],\n",
      "          [ 0.0021, -0.0430, -0.0808]],\n",
      "\n",
      "         [[-0.0430,  0.0388,  0.0201],\n",
      "          [-0.0108, -0.0540, -0.0015],\n",
      "          [ 0.0025,  0.0233,  0.0926]],\n",
      "\n",
      "         [[-0.0627,  0.0336,  0.0159],\n",
      "          [-0.0362, -0.0875, -0.0540],\n",
      "          [ 0.0509,  0.0676,  0.0236]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0231,  0.0295,  0.1127],\n",
      "          [ 0.0112,  0.0571,  0.0462],\n",
      "          [-0.0837, -0.0595, -0.1020]],\n",
      "\n",
      "         [[-0.0075,  0.0188, -0.1590],\n",
      "          [ 0.0244,  0.1043, -0.0314],\n",
      "          [ 0.1156,  0.0202, -0.0194]],\n",
      "\n",
      "         [[-0.0713, -0.0279, -0.0166],\n",
      "          [-0.0443, -0.0162,  0.0891],\n",
      "          [-0.0041,  0.0770,  0.0067]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0412, -0.0788,  0.0482],\n",
      "          [-0.0542,  0.0631,  0.0111],\n",
      "          [ 0.0016,  0.0460, -0.0085]],\n",
      "\n",
      "         [[-0.0208, -0.0586,  0.0815],\n",
      "          [ 0.1006,  0.0145, -0.1211],\n",
      "          [-0.0026, -0.0033, -0.0819]],\n",
      "\n",
      "         [[-0.1034, -0.0083,  0.0403],\n",
      "          [ 0.1105,  0.1540,  0.0227],\n",
      "          [ 0.0081, -0.0182,  0.0024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0235,  0.0226,  0.0786],\n",
      "          [ 0.0236,  0.0650,  0.0592],\n",
      "          [-0.0123, -0.0197, -0.0897]],\n",
      "\n",
      "         [[-0.0086, -0.0896, -0.0691],\n",
      "          [-0.1820, -0.1283,  0.0041],\n",
      "          [-0.0400,  0.0897,  0.1647]],\n",
      "\n",
      "         [[-0.0451,  0.0169,  0.0863],\n",
      "          [ 0.0829, -0.0940, -0.0527],\n",
      "          [-0.0371, -0.0766, -0.0595]]],\n",
      "\n",
      "\n",
      "        [[[-0.0302, -0.0075, -0.0083],\n",
      "          [ 0.0076,  0.0238, -0.0827],\n",
      "          [-0.0061, -0.1127,  0.0516]],\n",
      "\n",
      "         [[ 0.0477, -0.0776, -0.0354],\n",
      "          [ 0.0648,  0.0438,  0.0616],\n",
      "          [ 0.0569,  0.1495,  0.1265]],\n",
      "\n",
      "         [[-0.0019, -0.0040,  0.1050],\n",
      "          [-0.0078,  0.0062,  0.0835],\n",
      "          [ 0.1463,  0.1129,  0.0510]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0264,  0.0304,  0.0480],\n",
      "          [ 0.1074,  0.0539, -0.0495],\n",
      "          [ 0.0184, -0.0375, -0.0890]],\n",
      "\n",
      "         [[-0.0013, -0.0833,  0.0182],\n",
      "          [ 0.0146, -0.0213,  0.0591],\n",
      "          [ 0.0099,  0.0479,  0.0152]],\n",
      "\n",
      "         [[ 0.0660,  0.0168,  0.0706],\n",
      "          [ 0.0247, -0.0098, -0.0479],\n",
      "          [-0.0954, -0.0145, -0.0263]]]])), ('conv2.bias', tensor([-0.0420, -0.0274,  0.0185,  0.0164,  0.0229, -0.0475,  0.0392,  0.0296,\n",
      "         0.0498, -0.0743, -0.0321,  0.0335, -0.0819,  0.0521,  0.0365, -0.1317,\n",
      "        -0.0104,  0.0055,  0.0358, -0.0177, -0.0426, -0.0480, -0.0053, -0.0002,\n",
      "         0.0151, -0.0493,  0.0115, -0.0581,  0.0078,  0.0056, -0.0355, -0.0357,\n",
      "        -0.0259, -0.0080, -0.0233, -0.0144, -0.0304, -0.0444,  0.0102,  0.0661,\n",
      "        -0.0775, -0.0272, -0.0315, -0.0500,  0.0041,  0.0266, -0.0524,  0.0101,\n",
      "        -0.0245, -0.0568, -0.0215, -0.0634,  0.0289,  0.0088,  0.0787,  0.0255,\n",
      "        -0.0134, -0.0051, -0.0782, -0.0454,  0.0212, -0.0289,  0.0265,  0.0263])), ('bn2.weight', tensor([1.0814, 1.0204, 1.0663, 0.8585, 1.1731, 0.9414, 0.9643, 1.0109, 1.1337,\n",
      "        1.0256, 0.9880, 1.2002, 1.0795, 1.0816, 1.2361, 1.0394, 0.9715, 0.9455,\n",
      "        0.9473, 1.1116, 0.9599, 1.0368, 0.8424, 0.9737, 0.9859, 1.0154, 0.9022,\n",
      "        0.8699, 1.1120, 0.9791, 0.8093, 1.0671, 0.9876, 1.0292, 0.8881, 0.9464,\n",
      "        1.1016, 0.8545, 0.9244, 0.7802, 0.9970, 0.9263, 0.9430, 1.1577, 0.9541,\n",
      "        0.9436, 0.8700, 1.0169, 1.0133, 0.9780, 0.9775, 1.1211, 1.0700, 0.9073,\n",
      "        0.9092, 0.8719, 1.0082, 0.8542, 1.0141, 0.9029, 0.9270, 1.1198, 1.0475,\n",
      "        1.1540])), ('bn2.bias', tensor([ 0.0951, -0.0317, -0.1208, -0.1181,  0.0228, -0.0853, -0.0520, -0.0228,\n",
      "        -0.1838, -0.1538, -0.0702,  0.0260,  0.0304, -0.0520,  0.0881, -0.0530,\n",
      "        -0.0986, -0.1428, -0.1674, -0.0130, -0.0611, -0.0664, -0.2018, -0.0771,\n",
      "        -0.0821, -0.1096, -0.1369, -0.1377,  0.0623, -0.0903, -0.1376, -0.0176,\n",
      "        -0.0201, -0.0812, -0.1098, -0.1032, -0.0395, -0.1880, -0.1716, -0.1848,\n",
      "        -0.1484, -0.1937, -0.1676,  0.0172, -0.1963, -0.1260, -0.0273, -0.1372,\n",
      "        -0.0153, -0.1513, -0.1502,  0.0082, -0.0123, -0.2136, -0.0721, -0.1959,\n",
      "        -0.0660, -0.0357,  0.0071, -0.1406, -0.0485, -0.0450, -0.1024,  0.0073])), ('bn2.running_mean', tensor([-0.8494, -0.3839,  0.3449,  0.2227,  0.6571, -1.0811, -0.8916,  0.5064,\n",
      "         0.3636,  0.0050, -0.1085, -0.1974, -0.1461, -0.5636,  0.3725, -0.5573,\n",
      "        -0.6823, -0.1858, -0.0296,  0.4678, -0.6267, -1.2465, -0.4941, -1.1740,\n",
      "        -0.7377, -1.1238, -0.6997, -1.4423, -0.3465, -0.4112, -1.2446, -0.3115,\n",
      "        -0.1919, -0.8050,  0.1552, -0.9831,  0.3943, -0.1497,  0.3378,  0.2332,\n",
      "        -0.1917,  0.6329, -0.2166, -1.1648, -0.2848,  0.0901, -0.7140, -0.2018,\n",
      "        -0.8269, -0.2149,  0.5142, -1.2247, -0.0679, -0.7215,  0.1222,  0.5471,\n",
      "         0.1038,  0.5269,  0.6551, -0.1727, -0.0385, -0.1135, -0.4226, -0.6822])), ('bn2.running_var', tensor([2.1645, 2.8421, 1.2318, 1.7224, 2.0468, 2.8827, 1.5920, 2.3317, 1.6405,\n",
      "        1.8430, 2.4912, 1.4816, 1.9702, 1.9415, 2.4336, 0.8806, 2.3687, 1.5439,\n",
      "        1.7086, 2.2051, 1.3431, 2.3936, 1.3870, 1.6163, 1.5154, 2.1266, 0.9567,\n",
      "        2.3203, 2.8709, 1.4072, 1.9453, 2.2980, 2.0658, 1.5412, 2.4005, 2.1815,\n",
      "        2.7251, 1.1054, 2.0483, 2.6777, 1.4052, 1.0366, 2.5209, 2.0881, 1.0652,\n",
      "        2.0343, 2.1192, 0.6842, 2.5245, 0.6766, 2.3514, 1.4008, 2.1050, 1.0889,\n",
      "        1.2653, 1.3637, 1.7382, 1.6041, 1.3321, 1.7916, 1.7035, 2.4685, 2.2363,\n",
      "        1.4410])), ('bn2.num_batches_tracked', tensor(3750)), ('conv3.weight', tensor([[[[ 1.7146e-03, -6.4873e-03,  2.2191e-02],\n",
      "          [ 7.6885e-03, -6.4171e-03, -2.9755e-02],\n",
      "          [-7.4208e-02, -3.0004e-02, -3.3206e-02]],\n",
      "\n",
      "         [[ 2.2675e-02, -1.3327e-02,  2.4820e-02],\n",
      "          [-5.9282e-02, -6.7059e-02, -1.5786e-05],\n",
      "          [-2.7050e-03, -4.0333e-02,  7.0636e-02]],\n",
      "\n",
      "         [[-2.7999e-02, -3.3114e-02,  2.1905e-02],\n",
      "          [-7.4061e-02,  3.9812e-02, -1.0753e-01],\n",
      "          [-6.7458e-03,  5.2745e-02, -5.0431e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2738e-02, -2.4200e-02, -3.8094e-02],\n",
      "          [ 6.4041e-02,  8.1494e-02, -5.0041e-02],\n",
      "          [ 6.6485e-02,  9.6114e-02,  1.0091e-01]],\n",
      "\n",
      "         [[ 1.3463e-03,  3.7923e-03, -5.1940e-02],\n",
      "          [ 8.7285e-02, -1.7458e-02,  5.4531e-02],\n",
      "          [ 8.2985e-02,  6.3610e-02,  2.6832e-02]],\n",
      "\n",
      "         [[ 2.2687e-02,  5.1081e-02, -1.1674e-02],\n",
      "          [-1.2777e-02, -1.3150e-01, -6.2314e-02],\n",
      "          [ 1.1416e-01,  5.5925e-02, -8.2017e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9822e-02, -9.1785e-02, -3.4485e-02],\n",
      "          [ 5.1882e-02,  1.3114e-01,  1.7616e-01],\n",
      "          [-3.4932e-02,  3.6500e-02,  9.5974e-03]],\n",
      "\n",
      "         [[-1.7103e-02, -2.1406e-02,  1.0465e-01],\n",
      "          [ 3.5662e-02,  6.5588e-03, -1.9576e-01],\n",
      "          [-5.0705e-02,  3.3450e-02,  7.8008e-02]],\n",
      "\n",
      "         [[-7.6267e-03, -5.4718e-02, -2.9745e-02],\n",
      "          [ 6.4108e-02,  5.0244e-03,  2.8712e-02],\n",
      "          [-4.7620e-02,  4.4767e-02,  4.6798e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1046e-02,  6.0605e-03,  1.0470e-02],\n",
      "          [-6.6265e-02, -4.5693e-02, -5.4815e-02],\n",
      "          [-5.0933e-02, -3.9718e-02, -3.5860e-02]],\n",
      "\n",
      "         [[-5.5930e-02,  2.2454e-02,  1.5790e-02],\n",
      "          [-2.6916e-02, -6.8588e-02, -9.4616e-02],\n",
      "          [-1.1018e-02,  2.9728e-02, -5.2429e-02]],\n",
      "\n",
      "         [[-7.8536e-02, -1.4501e-02,  1.2063e-01],\n",
      "          [ 1.7227e-02, -9.9053e-02, -5.0532e-02],\n",
      "          [-2.1449e-03,  1.0047e-02,  6.0769e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5858e-02, -5.7673e-02, -5.7564e-02],\n",
      "          [ 4.3645e-02, -2.3378e-02, -9.8226e-03],\n",
      "          [ 4.4543e-02,  3.2154e-03,  4.6914e-03]],\n",
      "\n",
      "         [[ 1.1191e-02,  4.5078e-02,  2.7808e-02],\n",
      "          [-1.0110e-01,  2.3979e-03, -9.4143e-02],\n",
      "          [ 7.9865e-03, -2.1399e-02, -6.6632e-04]],\n",
      "\n",
      "         [[ 2.0587e-02,  4.1879e-02,  5.8635e-02],\n",
      "          [ 7.1580e-03, -1.6610e-01, -3.9774e-02],\n",
      "          [ 6.6212e-02,  3.6601e-02, -1.0406e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0291e-02, -1.2621e-02, -9.9475e-02],\n",
      "          [-3.2526e-02,  5.7713e-02,  1.6393e-02],\n",
      "          [ 3.5958e-02,  8.8439e-02,  3.6469e-02]],\n",
      "\n",
      "         [[ 2.8497e-02, -1.3530e-02, -6.3699e-02],\n",
      "          [ 3.0679e-02,  3.0860e-02,  5.8820e-02],\n",
      "          [-9.2713e-02,  1.4783e-01,  4.7399e-02]],\n",
      "\n",
      "         [[ 5.0549e-02,  7.0771e-02, -8.5257e-02],\n",
      "          [-6.9580e-02,  2.5563e-02,  5.3359e-03],\n",
      "          [-8.3495e-02,  1.1838e-01,  1.0914e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3075e-02, -1.0895e-01, -5.9151e-02],\n",
      "          [ 2.7423e-02, -4.4883e-02,  4.0384e-02],\n",
      "          [-2.6108e-02, -1.6842e-02, -6.3545e-02]],\n",
      "\n",
      "         [[ 3.2054e-03,  1.2395e-02, -2.1033e-02],\n",
      "          [ 5.1641e-03,  6.5137e-02, -3.5762e-02],\n",
      "          [ 3.1744e-02,  5.9839e-02, -1.5174e-02]],\n",
      "\n",
      "         [[ 2.8689e-03, -5.5433e-03,  2.4953e-02],\n",
      "          [ 7.3852e-03, -2.4002e-03,  3.2946e-02],\n",
      "          [ 1.0462e-02,  4.0309e-02, -7.5840e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9599e-02,  3.6089e-02,  1.0241e-02],\n",
      "          [ 6.7352e-02,  7.4160e-03, -1.2634e-01],\n",
      "          [ 4.9923e-02, -2.9630e-02, -5.0072e-02]],\n",
      "\n",
      "         [[ 5.5199e-02, -1.3032e-02, -6.1390e-02],\n",
      "          [-3.0797e-02, -3.7035e-02, -2.8663e-02],\n",
      "          [-6.2759e-03,  7.1669e-02, -7.3653e-02]],\n",
      "\n",
      "         [[-4.8474e-02,  3.7210e-02,  3.2337e-02],\n",
      "          [ 1.5708e-02,  8.2845e-02,  3.2716e-02],\n",
      "          [ 1.0873e-02,  1.7190e-01,  1.1504e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1335e-02, -1.7454e-02, -4.7884e-02],\n",
      "          [-1.4818e-01,  2.8131e-02, -1.8551e-02],\n",
      "          [ 2.2565e-02, -1.0970e-01,  2.4987e-02]],\n",
      "\n",
      "         [[-2.8613e-02,  3.8066e-02, -5.4861e-02],\n",
      "          [ 4.0897e-03, -7.3687e-02, -1.2334e-01],\n",
      "          [-1.2290e-01,  1.8501e-02,  7.9140e-03]],\n",
      "\n",
      "         [[ 5.0889e-02,  6.8648e-02,  2.3728e-02],\n",
      "          [ 3.9732e-02, -7.9966e-02,  2.3007e-04],\n",
      "          [-3.7016e-02,  1.3658e-02,  3.9450e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4288e-03, -4.1619e-02, -3.2444e-02],\n",
      "          [-4.5864e-02,  3.0991e-02,  2.4144e-02],\n",
      "          [-5.6110e-02, -7.6446e-02, -3.2891e-02]],\n",
      "\n",
      "         [[-7.3662e-02,  6.3283e-02,  6.2655e-02],\n",
      "          [ 1.3618e-05,  2.4330e-02,  4.2860e-02],\n",
      "          [-8.9465e-02,  6.9679e-02,  3.1178e-02]],\n",
      "\n",
      "         [[-1.9025e-02,  7.8216e-02,  2.0164e-02],\n",
      "          [-2.3229e-02, -1.2351e-02, -2.1102e-02],\n",
      "          [-1.1843e-01,  4.1394e-02, -2.5896e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.3091e-02, -4.2027e-02, -4.5991e-02],\n",
      "          [-2.8504e-02, -1.0373e-01,  5.9394e-02],\n",
      "          [-2.7982e-02,  3.9725e-02,  9.0684e-02]],\n",
      "\n",
      "         [[-4.9979e-03,  1.0662e-03, -7.5022e-03],\n",
      "          [-1.2865e-01, -2.5600e-03,  1.2305e-02],\n",
      "          [ 6.7931e-02, -4.2357e-02, -3.7891e-02]],\n",
      "\n",
      "         [[-1.3501e-02, -8.5031e-03, -3.0363e-02],\n",
      "          [ 8.6794e-02, -8.6073e-02,  1.9530e-02],\n",
      "          [ 8.8517e-02,  3.7751e-02, -3.6815e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6894e-02, -3.8954e-02, -5.1029e-02],\n",
      "          [ 6.3361e-02,  6.4620e-02,  6.1389e-02],\n",
      "          [ 1.4343e-02,  3.7787e-02,  2.3242e-02]],\n",
      "\n",
      "         [[ 1.0807e-02, -3.7621e-02, -3.0734e-02],\n",
      "          [ 5.3380e-02,  1.0487e-01,  6.0857e-02],\n",
      "          [-1.2028e-01,  8.4896e-02, -2.6382e-02]],\n",
      "\n",
      "         [[ 2.2723e-04,  1.0089e-02, -5.3684e-02],\n",
      "          [ 7.0228e-04,  4.2645e-02, -1.0059e-02],\n",
      "          [-1.3729e-02,  7.8437e-02,  8.1267e-02]]]])), ('conv3.bias', tensor([-1.9308e-02, -3.3877e-02, -4.3557e-03, -6.4970e-04,  2.5605e-02,\n",
      "         3.9484e-02, -3.8917e-03, -2.3629e-02,  1.0855e-02,  2.6110e-02,\n",
      "        -1.0800e-02, -1.1451e-02,  2.6875e-02,  1.8771e-02,  1.9552e-02,\n",
      "         1.3871e-02,  1.2231e-02, -2.2962e-03, -8.9719e-03,  2.8450e-02,\n",
      "         4.0254e-02, -2.5121e-03, -1.9754e-02,  9.3326e-03,  2.4782e-02,\n",
      "        -1.2988e-02,  1.0024e-02,  3.9918e-02,  9.1775e-03, -3.7931e-02,\n",
      "         3.1200e-02, -1.1675e-02,  1.3917e-02, -3.0839e-02, -2.7098e-02,\n",
      "        -2.4119e-02,  2.5987e-02, -1.9199e-03, -2.3996e-02, -2.1937e-02,\n",
      "         9.8537e-03,  1.8891e-03, -2.1737e-02,  4.9669e-03,  3.2700e-02,\n",
      "        -1.0015e-02,  2.2247e-02,  9.4849e-03, -2.5306e-02, -3.9055e-02,\n",
      "        -3.2956e-02,  2.0947e-02, -2.5265e-02, -3.8084e-02, -3.2881e-02,\n",
      "         3.1244e-02, -3.8367e-02,  1.0875e-02, -1.1667e-02,  9.6912e-04,\n",
      "        -4.2086e-02, -2.7384e-02,  2.3632e-02, -3.7349e-02, -4.1776e-02,\n",
      "         3.6845e-02,  3.0149e-02,  2.8587e-02, -2.1456e-03,  2.8816e-02,\n",
      "        -7.1367e-03, -4.1029e-02, -8.5734e-03, -3.0994e-02, -3.7762e-02,\n",
      "        -1.3652e-03,  1.6355e-03, -4.3032e-02, -3.1754e-02,  2.5583e-02,\n",
      "         2.7626e-02, -4.2244e-03,  2.9501e-02, -3.8410e-02,  3.5392e-02,\n",
      "        -3.7897e-02, -7.1865e-04,  2.9843e-03,  2.3158e-02,  1.4067e-02,\n",
      "         5.6552e-03,  3.7300e-02, -2.1103e-05,  3.4408e-02, -7.4258e-03,\n",
      "        -1.2299e-02,  1.6972e-02,  2.7383e-02, -2.9295e-03,  8.9093e-03,\n",
      "         2.7562e-02,  2.3416e-02,  3.4143e-02,  2.0843e-02,  3.0062e-02,\n",
      "        -3.0501e-03,  3.4455e-02,  1.3719e-02,  3.2564e-02,  2.5891e-02,\n",
      "        -2.2546e-02, -3.3217e-02,  3.6256e-02,  4.1675e-02,  9.6955e-03,\n",
      "         1.5833e-02, -4.0294e-02,  8.6458e-03,  3.1758e-02, -3.9002e-02,\n",
      "        -2.1546e-02, -1.6342e-02, -2.4471e-02,  2.2939e-02,  6.8895e-03,\n",
      "         1.4004e-02,  3.4112e-03, -2.3336e-02])), ('bn3.weight', tensor([1.1765, 1.1505, 1.1394, 1.1403, 1.0825, 1.1107, 1.2906, 1.2067, 1.2197,\n",
      "        1.1603, 1.1327, 1.2230, 1.0949, 1.0919, 1.1470, 1.1119, 1.0972, 1.3609,\n",
      "        1.1624, 1.1211, 1.2048, 1.1107, 1.2973, 1.1126, 1.3035, 1.2107, 1.2905,\n",
      "        1.0638, 1.0511, 1.2535, 1.1876, 1.2647, 1.1718, 1.1444, 1.1876, 1.2026,\n",
      "        1.2584, 1.1207, 1.1895, 1.1753, 1.1720, 1.1123, 1.1763, 1.3258, 1.2779,\n",
      "        1.2869, 1.1844, 1.1058, 1.1791, 1.0393, 1.1666, 1.1938, 1.2080, 1.3713,\n",
      "        1.1664, 1.1855, 1.1313, 1.1872, 1.1329, 1.1252, 1.0759, 1.2212, 1.1793,\n",
      "        1.1408, 1.1292, 1.0652, 1.0502, 1.2482, 1.3003, 1.1591, 1.1837, 1.2204,\n",
      "        1.0820, 1.0829, 1.2117, 1.2837, 1.0282, 1.1191, 1.1069, 1.2246, 1.0553,\n",
      "        1.2238, 1.1577, 1.2957, 1.2329, 1.1521, 1.1035, 1.1880, 1.1847, 1.1972,\n",
      "        1.1352, 1.2384, 1.2146, 1.2069, 1.2258, 1.1800, 1.3045, 1.1079, 1.3044,\n",
      "        1.1668, 1.1888, 1.2534, 1.1998, 1.2275, 1.1987, 1.1862, 1.2321, 1.1036,\n",
      "        1.1069, 1.1534, 1.2937, 1.2399, 1.0759, 1.2159, 1.1448, 1.1207, 1.1221,\n",
      "        1.1969, 1.1774, 1.2714, 1.2980, 1.2219, 1.1335, 1.2098, 1.2438, 1.2570,\n",
      "        1.1185, 1.1064])), ('bn3.bias', tensor([-5.4245e-02,  6.0525e-02, -1.5155e-03,  2.8989e-03, -9.3604e-03,\n",
      "         5.2315e-03,  2.8038e-02,  7.6424e-02,  4.4050e-02,  7.5724e-02,\n",
      "        -6.8302e-02, -1.5089e-03,  5.5306e-02, -3.7923e-02,  1.5106e-02,\n",
      "        -4.8154e-02,  1.2750e-02,  9.7591e-02,  2.1747e-02,  5.8071e-02,\n",
      "        -3.4807e-03,  1.1821e-02,  3.8429e-02,  1.9466e-02,  8.5262e-02,\n",
      "         4.1065e-02,  1.8959e-02,  2.3139e-02, -7.0273e-02,  4.7320e-02,\n",
      "         2.8900e-02,  9.5194e-02,  2.5537e-02,  8.2328e-02,  1.2905e-01,\n",
      "         2.0836e-02,  6.7833e-02, -7.9946e-02,  1.3691e-02,  1.5975e-02,\n",
      "         6.3245e-02,  2.7780e-02, -7.1633e-02,  8.4491e-02,  5.6085e-02,\n",
      "         2.5475e-02, -2.7545e-02,  7.7113e-02, -4.4959e-02, -6.1299e-02,\n",
      "         1.8215e-02, -1.0911e-02, -2.0862e-03,  1.0758e-01,  6.0201e-02,\n",
      "         6.4833e-02,  1.0277e-02, -1.5477e-02,  3.6554e-02, -9.2323e-03,\n",
      "         9.5363e-05,  1.2689e-02,  1.2606e-02,  4.0092e-02,  6.7128e-02,\n",
      "        -5.8066e-02, -7.3720e-02,  5.4496e-02, -6.4093e-03, -4.5468e-02,\n",
      "         7.4788e-03,  6.0482e-02, -7.9118e-03,  8.9137e-02,  2.5586e-03,\n",
      "         3.9518e-02, -1.8719e-02, -6.2406e-02, -3.6661e-02,  4.7535e-02,\n",
      "         2.0037e-03,  3.8804e-02, -3.0205e-02,  4.7795e-02, -2.6708e-02,\n",
      "        -6.6999e-02, -8.1815e-03, -3.4677e-02,  4.7282e-02, -1.1144e-03,\n",
      "         4.2769e-02,  1.2915e-03,  8.0614e-03,  2.0330e-02,  1.7646e-02,\n",
      "         2.0927e-02,  1.3188e-01, -3.4767e-02,  6.4750e-02,  3.4596e-03,\n",
      "         3.1903e-02,  4.9430e-02,  3.5264e-02,  3.2752e-02,  1.0774e-02,\n",
      "         8.8005e-03, -5.4038e-03,  1.0439e-02, -6.1803e-03,  5.1288e-02,\n",
      "         4.3081e-02,  2.6736e-03, -1.9533e-02,  7.4497e-03,  3.4839e-02,\n",
      "        -6.3157e-02,  6.0970e-03,  7.9233e-02,  8.6702e-03,  8.2774e-02,\n",
      "         1.3212e-03,  3.9819e-02,  4.0500e-02,  6.2670e-02,  2.5380e-02,\n",
      "         7.1997e-02, -1.5806e-02, -1.6118e-03])), ('bn3.running_mean', tensor([-1.2644e-01, -2.8427e+00,  8.9120e-02, -1.0958e+00, -5.8104e-01,\n",
      "        -1.1182e+00,  9.4870e-01, -1.3634e-01,  1.1981e-01, -5.5162e-01,\n",
      "        -2.5389e-01,  6.1930e-02, -2.3988e+00,  4.1630e-01, -3.0703e-01,\n",
      "        -1.7869e+00,  6.7288e-01, -5.4445e-01,  6.5269e-01,  1.2264e-01,\n",
      "        -1.7320e+00,  1.1779e+00, -1.8237e+00, -8.3748e-01, -1.1671e+00,\n",
      "        -1.9155e+00, -1.3796e+00, -1.2998e+00, -6.0323e-01,  5.1087e-03,\n",
      "         7.0694e-01, -3.7622e-02, -2.2440e+00,  8.1503e-01,  6.3311e-01,\n",
      "        -1.6082e+00, -1.3554e+00, -2.6627e+00, -1.6840e-01, -1.4141e+00,\n",
      "         1.8254e-01, -2.4411e+00, -7.6645e-01, -1.0618e+00, -9.8044e-01,\n",
      "        -6.4013e-01,  7.1125e-01, -1.1803e+00, -1.0962e+00, -6.4779e-01,\n",
      "         9.3239e-01,  3.8121e-01, -2.0683e-01,  8.0210e-01, -2.9415e-01,\n",
      "         5.9855e-02,  5.2135e-02, -9.4910e-02, -1.7680e+00, -1.7029e+00,\n",
      "        -4.7061e-01, -8.5673e-01, -4.0636e-01, -3.5149e-01, -9.4514e-01,\n",
      "        -2.6939e-02, -6.5214e-01, -1.0872e+00,  6.5062e-01, -1.9772e+00,\n",
      "        -7.2822e-01, -5.9033e-01,  8.1795e-01,  9.3683e-02,  7.9593e-01,\n",
      "         1.0351e+00,  1.7942e+00, -7.4887e-01,  4.0663e-03, -8.9562e-01,\n",
      "         1.0100e+00, -2.1036e-01, -2.6737e-01,  8.2931e-01, -3.9314e-01,\n",
      "        -2.3756e+00, -1.0572e+00,  6.9651e-01, -7.1231e-01, -4.8467e-01,\n",
      "        -2.8317e+00,  1.9737e-01, -6.4316e-01,  2.2641e+00, -1.8182e-01,\n",
      "         6.0314e-01,  8.1255e-01, -2.1482e-01,  3.6318e-01,  1.7081e+00,\n",
      "        -1.1551e+00,  4.2427e-02,  3.0235e-01,  9.2349e-01,  1.4790e-01,\n",
      "        -6.9253e-04,  2.5202e-01, -1.0276e+00, -1.8102e-03,  1.1206e+00,\n",
      "         3.4808e-01, -8.6163e-02, -2.2430e+00, -1.0317e+00,  2.4635e-01,\n",
      "         1.7484e-01, -9.0909e-01, -1.0934e+00,  2.0419e+00, -1.7715e+00,\n",
      "        -9.2504e-01,  1.1624e+00, -4.3756e-01, -3.4423e-02,  9.6955e-01,\n",
      "        -1.0694e-02, -1.4144e+00,  1.0988e+00])), ('bn3.running_var', tensor([4.4296, 2.8732, 4.1586, 4.2703, 3.0586, 2.8989, 3.6621, 2.7682, 4.4390,\n",
      "        3.1409, 3.5093, 2.6682, 3.6892, 3.1840, 3.7478, 2.9714, 3.0007, 4.6340,\n",
      "        3.2792, 4.9866, 5.0784, 2.9789, 3.9671, 3.0708, 5.8669, 4.1072, 3.3439,\n",
      "        2.4753, 3.2646, 4.6741, 3.1688, 3.8054, 2.4002, 4.0027, 3.8312, 2.7322,\n",
      "        3.5113, 2.8574, 5.0377, 3.0143, 3.6588, 2.7780, 2.2532, 3.3853, 4.3655,\n",
      "        3.0428, 2.9015, 3.1664, 2.6029, 2.2684, 4.7493, 3.8219, 3.6923, 3.5265,\n",
      "        4.1554, 4.3816, 3.8776, 3.1780, 2.2547, 2.4737, 3.6786, 4.7802, 4.1769,\n",
      "        3.9545, 3.7790, 3.7922, 2.8467, 4.6874, 3.0717, 4.1182, 4.5397, 2.7639,\n",
      "        2.5434, 4.3007, 4.3106, 2.4576, 2.6544, 3.0955, 3.2146, 2.4546, 3.6353,\n",
      "        4.3150, 2.8654, 3.2172, 3.4663, 4.1925, 2.6318, 3.1919, 5.0839, 3.3715,\n",
      "        2.9594, 3.4429, 3.3558, 3.8835, 4.3697, 3.8486, 4.4421, 3.3647, 4.3412,\n",
      "        3.8500, 3.3741, 2.5299, 4.3446, 4.1966, 2.4940, 3.6428, 3.0997, 2.6912,\n",
      "        3.1343, 5.2057, 4.7773, 2.2776, 2.8827, 3.8108, 3.0148, 3.0977, 3.3527,\n",
      "        3.0168, 3.6907, 4.0287, 4.1326, 2.8955, 3.8493, 3.5131, 3.3496, 4.4339,\n",
      "        2.7515, 4.8852])), ('bn3.num_batches_tracked', tensor(3750)), ('fc.weight', tensor([[-0.0239, -0.0069, -0.0411,  ..., -0.0375, -0.0443, -0.0051],\n",
      "        [-0.0073, -0.1677, -0.0699,  ..., -0.0678, -0.0176, -0.1559],\n",
      "        [-0.0419, -0.0083, -0.0610,  ...,  0.0586,  0.1399, -0.0191],\n",
      "        ...,\n",
      "        [ 0.0066, -0.0113, -0.0331,  ...,  0.0141, -0.0128,  0.0252],\n",
      "        [-0.1745,  0.0234,  0.0760,  ..., -0.0355, -0.0478,  0.0197],\n",
      "        [-0.0946,  0.0395,  0.1058,  ..., -0.1329, -0.0432,  0.0398]])), ('fc.bias', tensor([-0.0340,  0.0415,  0.0181, -0.0189,  0.0375,  0.0160, -0.0065,  0.0316,\n",
      "         0.0303, -0.0491]))])\n",
      "=======================\n",
      " Test set: Average loss: 0.0726, Accuracy: 0.603\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# 모델 불러오기\n",
    "# torch.Load()\n",
    "import torch\n",
    "import os\n",
    "\n",
    "save_path = 'weights/'\n",
    "model_name = 'CNN'\n",
    "state_dict = torch.load(save_path+model_name)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "cnn.load_state_dict(state_dict)\n",
    "# cnn.conv1.weight.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 불러오기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorboard  \n",
    "tensorboard는 모델학습 과정의 loss나 기타 지표를 확인해서 학습이 잘되고 있는지, 모델 테스트 성능이  \n",
    "어떻게 나오는지를 시각화해줍니다.   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "!pip install tensorboard"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorboard in /home/hchang/Working/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (44.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (1.40.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (0.13.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (1.35.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (3.18.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/hchang/Working/lib/python3.8/site-packages (from tensorboard) (0.37.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/hchang/Working/lib/python3.8/site-packages (from grpcio>=1.24.3->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hchang/Working/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/hchang/Working/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hchang/Working/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/hchang/Working/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/hchang/Working/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/hchang/Working/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/hchang/Working/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/hchang/Working/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/hchang/Working/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/hchang/Working/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# writer 를 정의\n",
    "writer = SummaryWriter('runs/cnn/')\n",
    "\n",
    "# writer.ad.scalar를 통해서 손실함수 값, 또는 정확도를 기록할 수 있습니다.\n",
    "\n",
    "writer.add_scalar(\"그룹/변수명\", 변수, iter)\n",
    "# ex: 그룹 = train or valid 변수명 : Loss or acc\n",
    "\n",
    "\n",
    "writer.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "먼저 runs 폴더를 만들고 그 안에 cnn 폴더를 만들어주세요.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quiz (Normal)  \n",
    "add_scalar는 train, test함수에서 어느 줄에 삽입해야 할까요?  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if pre_trained:\n",
    "    model_dict = torch.load(save_path+model_name)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "def train(epoch, model, loss_func, train_loader, valid_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        train_loss = loss_func(y_pred, y)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch+1} | Batch Status: {batch_index*len(x)}/{len(train_loader.dataset)} \\\n",
    "            ({100. * batch_index * batch_size / len(train_loader.dataset):.0f}% | Loss: {train_loss.item():.6f}')\n",
    "            torch.save(model.state_dict(), save_path + model_name)\n",
    "\n",
    "    for batch_index, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        val_loss = loss_func(y_pred, y)\n",
    "        \n",
    "def test(model, loss_func, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss += loss_func(y_pred, y).item()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        # torch.eq : Computes element-wise equality. return counts value\n",
    "        correct_count += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'=======================\\n Test set: Average loss: {test_loss:.4f}, Accuracy: {correct_count/len(test_loader.dataset):.3}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "kernel_size = 3\n",
    "stride = 2\n",
    "pre_trained = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "save_path = './weights/'\n",
    "config_path = './configs/'\n",
    "model_name = 'cnn.pth'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cnn = CNN(C=1, W=28, H=28, K=3, S=2) \n",
    "cnn = cnn.to(device)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "writer = SummaryWriter('runs/cnn/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13\n",
      "6\n",
      "2\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "!tensorboard --logdir \"runs/cnn\"\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-11-19 17:32:38.503560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-19 17:32:38.503638: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-11-19 17:32:42.035206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-19 17:32:42.035384: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-19 17:32:42.035465: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Gift-of-Mia): /proc/driver/nvidia/version does not exist\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.6.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Working': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "026aceb1435085fcef523649cdfc9385a4a55dbc5c65435142607853821fa50a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}