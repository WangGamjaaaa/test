{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27563e3",
   "metadata": {},
   "source": [
    "![torchman](../Practice/imgs/torchman.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8d800",
   "metadata": {},
   "source": [
    "이번 차례에는 머신러닝 파이프라인을 살펴보고 데이터를 어떻게 텐서를 통해 표현하는지 살펴보겠습니다  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a9f436",
   "metadata": {},
   "source": [
    "# Deep learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b59941",
   "metadata": {},
   "source": [
    "![dlpl](../Practice/imgs/pipelin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb45cb",
   "metadata": {},
   "source": [
    "저희가 지금까지 배운 수 체계에는 스칼라, 벡터, 행렬, 텐서가 있었습니다.  \n",
    "그리고 많은 머신러닝 책에서는 아래와 같이 표기합니다.  \n",
    "여러 모듈과 메소드를 통해 파이토치에서 어떻게 텐서를 조작하는지 알아보겠습니다  \n",
    "\n",
    "[https://pytorch.org/](https://pytorch.org/)\n",
    "\n",
    "git clone https://github.com/SunCreation/pytorch_master.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1ca1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085327a",
   "metadata": {},
   "source": [
    "$${스칼라 : x \\quad  }$$\n",
    "$$벡터 : \\mathbf x \\quad n  $$\n",
    "$$행렬 : \\mathbf X \\quad m \\times n  $$\n",
    "$$텐서 : \\mathcal {X} \\quad l \\times m \\times n \\times \\dots $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4148613",
   "metadata": {},
   "source": [
    "먼저 들어가기 앞서서 프로그래밍 초반에 배우는 데이터의 타입을 떠올려보겠습니다.  \n",
    "대표적으로 다음과 같습니다. \n",
    "1. Int  \n",
    "2. Double  \n",
    "3. Float  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32141ac7",
   "metadata": {},
   "source": [
    "일반적으로 torch의 여러가지 텐서모듈을 통해 위의 데이터타입을 가지는 텐서를 생성할 수 있습니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8830d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "from torch import FloatTensor as ftensor\n",
    "from torch import DoubleTensor as dtensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc720cd",
   "metadata": {},
   "source": [
    "텐서 객체는 다음과 같은 형태로 할당하게 됩니다.  \n",
    "tensor = tensor(data, dtype=float32, device='cpu')  \n",
    "텐서 객체를 생성하기 위한 파라미터와 인자는 data, dtype, device가 있습니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89f1bc",
   "metadata": {},
   "source": [
    "## 1. 스칼라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c5668",
   "metadata": {},
   "source": [
    "dtype과 device를 지정하지 않으면 자동으로 dtype을 식별하고 device는 cpu로 할당하게 됩니다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f80b0",
   "metadata": {},
   "source": [
    ".item()을 통하여 텐서 객체 내의 단일 스칼라 값을 뽑아낼 수 있습니다. item 메소드는 반드시 스칼라 텐서에서 호출해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fac458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = th.tensor(0.1)\n",
    "type(scalar.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc3834",
   "metadata": {},
   "source": [
    "## 2. 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f313e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "nparray = np.zeros((1, 2, 3))\n",
    "vector = th.tensor(nparray)\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7368a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = tensor([1, 2, 3, 4])\n",
    "vec2 = dtensor([1, 2, 3 ,4])\n",
    "vec3 = ftensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6c67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) tensor([1., 2., 3., 4.], dtype=torch.float64) tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "print(vec1, vec2, vec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd95931",
   "metadata": {},
   "source": [
    "data에 들어갈 수 있는 컨테이너는 List, Tuple, Numpy array입니다.  \n",
    "파이토치에서 텐서 객체를 만드는 방법은 기존의 numpy와 매우 유사합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8b07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 컴프리헨션으로 100개의 텐서를 리스트에 넣으세요.\n",
    "tensor_q = [tensor([x]) for x in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfebf10",
   "metadata": {},
   "source": [
    "## 3. 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc18d6",
   "metadata": {},
   "source": [
    "이제 행렬 텐서를 만들어보겠습니다.  \n",
    "데이터타입을 행렬로 다루기 시작한다면 device를 gpu로 지정하는게 좋습니다.  \n",
    "이제 데이터를 일일히 생성하기 힘드므로 rand를 사용하겠습니다.  \n",
    "rand를 잘 활용하기 위해 시드를 고정하겠습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6cc23",
   "metadata": {},
   "source": [
    "![tensor](../Practice/imgs/tensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8374b061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0290, 0.4019],\n",
       "         [0.2598, 0.3666]]),\n",
       " tensor([[0.0583, 0.7006],\n",
       "         [0.0518, 0.4681]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.manual_seed(1234)\n",
    "mat = th.rand((2, 2))\n",
    "mat1 = th.rand(2, 2)\n",
    "mat, mat1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2974c4",
   "metadata": {},
   "source": [
    "## 4. 텐서  \n",
    "이제 3차원 이상의 텐서를 만들어보겠습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0054c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat3 = th.rand(3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57a42d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2837, 0.6567, 0.2388, 0.7313, 0.6012],\n",
       "         [0.3043, 0.2548, 0.6294, 0.9665, 0.7399],\n",
       "         [0.4517, 0.4757, 0.7842, 0.1525, 0.6662],\n",
       "         [0.3343, 0.7893, 0.3216, 0.5247, 0.6688]],\n",
       "\n",
       "        [[0.8436, 0.4265, 0.9561, 0.0770, 0.4108],\n",
       "         [0.0014, 0.5414, 0.6419, 0.2976, 0.7077],\n",
       "         [0.4189, 0.0655, 0.8839, 0.8083, 0.7528],\n",
       "         [0.8988, 0.6839, 0.7658, 0.9149, 0.3993]],\n",
       "\n",
       "        [[0.1100, 0.2541, 0.4333, 0.4451, 0.4966],\n",
       "         [0.7865, 0.6604, 0.1303, 0.3498, 0.3824],\n",
       "         [0.8043, 0.3186, 0.2908, 0.4196, 0.3728],\n",
       "         [0.3769, 0.0108, 0.9455, 0.7661, 0.2634]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a1ca0",
   "metadata": {},
   "source": [
    "# 퀴즈 (Easy)  \n",
    "1) !nvidia-smi 를 통해 현재 gpu의 메모리 사용량을 확인하세요\n",
    "2) 크기가 (100, 100, 100)인 3차원 랜덤 텐서를 gpu 메모리에 할당하세요\n",
    "3) 다시 !nvidia-smi를 통해 gpu 메모리 사용량이 얼마나 늘었는지 계산해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ead658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 24 10:57:42 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   38C    P0    21W /  N/A |      5MiB /  7982MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      7166      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9afb6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat4 = th.rand(100, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59bef268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17643/2718875410.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor(mat4, device = 'cuda')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1880, 0.5174, 0.7849,  ..., 0.8757, 0.7378, 0.9949],\n",
       "         [0.2338, 0.2153, 0.2073,  ..., 0.9475, 0.9515, 0.5817],\n",
       "         [0.2920, 0.8040, 0.4826,  ..., 0.1071, 0.0648, 0.6555],\n",
       "         ...,\n",
       "         [0.7855, 0.1410, 0.9706,  ..., 0.1771, 0.9385, 0.0165],\n",
       "         [0.7791, 0.1056, 0.2174,  ..., 0.0187, 0.4807, 0.9493],\n",
       "         [0.4512, 0.4553, 0.6969,  ..., 0.3192, 0.1100, 0.9460]],\n",
       "\n",
       "        [[0.3930, 0.8984, 0.0452,  ..., 0.1375, 0.9205, 0.1624],\n",
       "         [0.3788, 0.4968, 0.6348,  ..., 0.0284, 0.4027, 0.5966],\n",
       "         [0.8497, 0.3773, 0.8951,  ..., 0.9170, 0.6660, 0.1428],\n",
       "         ...,\n",
       "         [0.2665, 0.5249, 0.4629,  ..., 0.1564, 0.4731, 0.1355],\n",
       "         [0.6756, 0.1651, 0.8155,  ..., 0.7816, 0.1069, 0.7070],\n",
       "         [0.2158, 0.1250, 0.4128,  ..., 0.7782, 0.0969, 0.2174]],\n",
       "\n",
       "        [[0.0680, 0.6999, 0.3438,  ..., 0.9838, 0.7281, 0.2104],\n",
       "         [0.3052, 0.9725, 0.6939,  ..., 0.5454, 0.1958, 0.2802],\n",
       "         [0.8390, 0.6447, 0.2936,  ..., 0.3189, 0.8806, 0.2827],\n",
       "         ...,\n",
       "         [0.3765, 0.8910, 0.7992,  ..., 0.8897, 0.7171, 0.1293],\n",
       "         [0.9177, 0.8559, 0.8610,  ..., 0.1765, 0.6734, 0.4880],\n",
       "         [0.1857, 0.5288, 0.5564,  ..., 0.3053, 0.0150, 0.3827]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0786, 0.7818, 0.2691,  ..., 0.9548, 0.0696, 0.4913],\n",
       "         [0.8999, 0.6765, 0.5142,  ..., 0.8719, 0.3097, 0.0505],\n",
       "         [0.7922, 0.3886, 0.7317,  ..., 0.2583, 0.1777, 0.5935],\n",
       "         ...,\n",
       "         [0.3779, 0.5152, 0.5627,  ..., 0.0496, 0.2605, 0.5204],\n",
       "         [0.9877, 0.7042, 0.9163,  ..., 0.7261, 0.3726, 0.7087],\n",
       "         [0.2136, 0.3232, 0.9814,  ..., 0.3854, 0.1371, 0.2111]],\n",
       "\n",
       "        [[0.2282, 0.3859, 0.9297,  ..., 0.2974, 0.0468, 0.5752],\n",
       "         [0.0253, 0.1096, 0.9009,  ..., 0.2867, 0.0259, 0.1042],\n",
       "         [0.4537, 0.3037, 0.8973,  ..., 0.8670, 0.7564, 0.0730],\n",
       "         ...,\n",
       "         [0.8077, 0.3427, 0.5790,  ..., 0.0057, 0.4005, 0.6711],\n",
       "         [0.6941, 0.8863, 0.7567,  ..., 0.5887, 0.1433, 0.4735],\n",
       "         [0.1308, 0.9946, 0.6369,  ..., 0.8043, 0.0771, 0.6665]],\n",
       "\n",
       "        [[0.4395, 0.3424, 0.4224,  ..., 0.1033, 0.0823, 0.1497],\n",
       "         [0.5427, 0.5487, 0.7467,  ..., 0.6081, 0.4836, 0.5589],\n",
       "         [0.4837, 0.6993, 0.5925,  ..., 0.0748, 0.0406, 0.9092],\n",
       "         ...,\n",
       "         [0.2085, 0.9282, 0.9618,  ..., 0.7949, 0.5278, 0.3480],\n",
       "         [0.3172, 0.7836, 0.0281,  ..., 0.1967, 0.5515, 0.9704],\n",
       "         [0.1081, 0.0754, 0.4566,  ..., 0.2490, 0.6891, 0.8910]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(mat4, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70d30c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 24 11:01:29 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   40C    P0    31W /  N/A |    989MiB /  7982MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      7166      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    0   N/A  N/A     17643      C   .../yhy/anaconda3/bin/python      981MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495573f6",
   "metadata": {},
   "source": [
    "5MiB에서 989MiB로 값이 바뀌는 것을 확인함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a116e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21e15cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 24 11:09:31 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   40C    P8     6W /  N/A |    988MiB /  7982MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      7166      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    0   N/A  N/A     17643      C   .../yhy/anaconda3/bin/python      979MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2574e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1437800297.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_17643/1437800297.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mat4.del tensor\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mat4 del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c47112",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache( )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a39879ae9ccb927afc0cf2ce944a9e89e93d1a75059893b60dcfa8646ca8faf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
